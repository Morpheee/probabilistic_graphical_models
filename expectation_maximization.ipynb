{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from pprint import pprint\n",
    "from scipy.special import logsumexp\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "source : http://approximateinference.org/2017/accepted/Zinkov2017.pdf\n",
    "source : https://towardsdatascience.com/implement-expectation-maximization-em-algorithm-in-python-from-scratch-f1278d1b9137"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/X_station_day.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.rename(columns={\"precipitations\": \"current_precipitations\"}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EM\n",
    " M-step :\n",
    "\n",
    "$$ \\pi = \\frac{\\sum_{i=1}^{n}\\mathcal{Q}(y^i=1|x^i)}{n} $$\n",
    "\n",
    "$$ \\mu_j = \\frac{\\sum_{i=1}^{n}x^i\\mathcal{Q}(y^i=j|x^i)}{\\sum_{i=1}^{n}\\mathcal{Q}(y^i=j|x^i)} $$\n",
    "\n",
    "$$ \\Sigma_j = \\frac{\\sum_{i=1}^{n}\\mathcal{Q}(y^i=j|x^i)(x^i-\\mu_j)(x^i-\\mu_j)^T}{\\sum_{i=1}^{n}\\mathcal{Q}(y^i=j|x^i)} $$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1 dimension"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EM_1D():\n",
    "    def __init__(self, x: np.ndarray, nb_dist=2, split_ratio=0.1, threshold=0.01, minimum_sigma=1e-5, talk=False):\n",
    "        self.talk = talk  # whether to display information or not\n",
    "        self.threshold = threshold  # threshold ratio to trigger stop_fitting\n",
    "        self.minimum_sigma = minimum_sigma  # to avoid sigma being 0\n",
    "        self.stop_fitting = False  # stop fitting if maximum iterations reached or threshold passed\n",
    "        self.nb_dist = nb_dist  # number of distributions to fit\n",
    "\n",
    "        self.split_ratio = split_ratio  # part of x to keep to initialize the parameters\n",
    "        self.x_all = x  # backup of whole x data\n",
    "        self.idx_sample = None  # index of x_sample for initialization\n",
    "        self.x_sample = None  # sample for initialization\n",
    "        self.x = None  # training part of x\n",
    "        self.split_x()  # fill x_sample, idx_sample and x\n",
    "\n",
    "        self.mu = None  # average\n",
    "        self.sigma = None  # standard deviation\n",
    "        self.w = None  # weights\n",
    "        self.init_params()  # initialize the above\n",
    "\n",
    "        self.history = None  # history\n",
    "        self.init_history()  # initialize history\n",
    "\n",
    "        self.r = None  # declare r to anticipate fit()\n",
    "\n",
    "        self.initial_record = None  # declare variable, used in average_fit()\n",
    "        self.history_record = None  # declare variable, used in average_fit()\n",
    "        self.clustered_distributions = None  # declare variable, used in average_fit()\n",
    "\n",
    "        self.colors = [\"blue\", \"red\", \"orange\", \"green\", \"magenta\"]\n",
    "\n",
    "    def split_x(self):\n",
    "        self.idx_sample = rng.choice(np.arange(self.x_all.shape[0]),\n",
    "                                     replace=False,\n",
    "                                     size=int(self.x_all.shape[0] * self.split_ratio))\n",
    "        self.x_sample = self.x_all[self.idx_sample]\n",
    "        self.x = np.delete(self.x_all, self.idx_sample, axis=0)\n",
    "\n",
    "    def init_params(self):\n",
    "        mu = rng.normal(loc=np.mean(self.x_sample),\n",
    "                        scale=5,\n",
    "                        size=self.nb_dist)\n",
    "        sigma = np.abs(rng.normal(loc=np.sqrt(np.var(self.x_sample)),\n",
    "                                  scale=2,\n",
    "                                  size=self.nb_dist))\n",
    "        w = np.abs(rng.normal(loc=1,\n",
    "                              scale=0.2,\n",
    "                              size=self.nb_dist))\n",
    "        w /= w.sum()\n",
    "        if self.talk:\n",
    "            print(\"Initial parameters :\")\n",
    "            print(\"\\t - mu :    {}\".format(np.round(mu, 2)))\n",
    "            print(\"\\t - sigma : {}\".format(np.round(sigma, 2)))\n",
    "            print(\"\\t - w :     {}\".format(np.round(w, 2)))\n",
    "        self.mu, self.sigma, self.w = mu, sigma, w\n",
    "\n",
    "    def init_history(self):\n",
    "        history = {\"mu\": [self.mu],\n",
    "                   \"sigma\": [self.sigma],\n",
    "                   \"w\": [self.w]}\n",
    "        self.history = history\n",
    "\n",
    "    def update_h(self):\n",
    "        self.history[\"mu\"].append(self.mu)\n",
    "        self.history[\"sigma\"].append(self.sigma)\n",
    "        self.history[\"w\"].append(self.w)\n",
    "\n",
    "    def e_step(self):\n",
    "        x = self.x[None, :]\n",
    "        mu = self.mu[:, None]\n",
    "        sigma = self.sigma[:, None]\n",
    "        # r is the likelyhood of each point of x given the normal distribution N(mu,sigma)\n",
    "        self.r = stats.norm.pdf(x, mu, sigma)\n",
    "        self.r = self.r / self.r.sum(axis=0)\n",
    "\n",
    "    def m_step(self):\n",
    "        n = self.x.shape[0]\n",
    "        self.w = np.sum(self.r, axis=1) / n\n",
    "        self.mu = np.sum(self.x * self.r, axis=1) / np.sum(self.r, axis=1)\n",
    "        sigma = []\n",
    "        for j in range(self.nb_dist):\n",
    "            sigma.append(\n",
    "                np.sqrt(np.sum(self.r[j, :] * (self.x - self.mu[j]) * (self.x - self.mu[j])) / np.sum(self.r[j, :])))\n",
    "            if sigma[-1] == 0:\n",
    "                print(\n",
    "                    \"WARNING : sigma == 0, set sigma to minimum_sigma = {}\".format(self.minimum_sigma))\n",
    "                sigma[-1] = self.minimum_sigma\n",
    "        self.sigma = np.array(sigma)\n",
    "\n",
    "    def fit(self, max_iters=100, plot=False):\n",
    "        self.stop_fitting = False\n",
    "        for i in range(max_iters):\n",
    "            if self.talk and i % int(max_iters // 100 + 1) == 0:\n",
    "                print(\"{} %\".format(int(i / max_iters * 100)).rjust(5), end=\"\\r\")\n",
    "\n",
    "            self.e_step()\n",
    "            self.m_step()\n",
    "            self.update_h()\n",
    "\n",
    "            self.check_change()\n",
    "            if self.stop_fitting:\n",
    "                break\n",
    "\n",
    "        if self.talk:\n",
    "            print(\"\\n\")\n",
    "            if self.stop_fitting:\n",
    "                print(\"Threshold reached, less than {} % difference.\".format(self.threshold * 100))\n",
    "            else:\n",
    "                print(\"100 %\")\n",
    "            print(\"Final parameters :\\n\\tmu :    {}\\n\\tsigma : {}\\n\\tw :     {}\".format(self.history[\"mu\"][-1],\n",
    "                                                                                        self.history[\"sigma\"][-1],\n",
    "                                                                                        self.history[\"w\"][-1]))\n",
    "\n",
    "        if plot:\n",
    "            self.plot_progression()\n",
    "\n",
    "    def check_change(self):\n",
    "        mu_old = self.history[\"mu\"][-2]\n",
    "        sigma_old = self.history[\"sigma\"][-2]\n",
    "        w_old = self.history[\"w\"][-2]\n",
    "        if any(self.mu == 0):\n",
    "            delta_mu = np.max(np.abs((mu_old - self.mu) / (self.mu + 1)))\n",
    "        else:\n",
    "            delta_mu = np.max(np.abs((mu_old - self.mu) / self.mu))\n",
    "        delta_sigma = np.max(np.abs((sigma_old - self.sigma) / self.sigma))\n",
    "        if any(self.w == 0):\n",
    "            delta_w = np.max(np.abs((w_old - self.w) / (self.w + 1)))\n",
    "        else:\n",
    "            delta_w = np.max(np.abs((w_old - self.w) / self.w))\n",
    "        delta = max(delta_mu, delta_sigma, delta_w)\n",
    "        if delta < self.threshold:\n",
    "            self.stop_fitting = True\n",
    "\n",
    "    def average_fit(self, runs=3, max_iters=100, plot=True, plot_title=\"\"):\n",
    "        \"\"\"\n",
    "        to avoid initialization issues, average over [runs] fit() and different initializations.\n",
    "        :param plot_title: title of the plot of plot\n",
    "        :param runs: number of fit() to execute\n",
    "        :param max_iters: maximum number of iterations for each fit()\n",
    "        :param plot: plot the final result, average of all fit()\n",
    "\n",
    "        updates to history to every parameters fo every fit() (for plotting purpose) and parameters to average of every run.\n",
    "        \"\"\"\n",
    "\n",
    "        initial_record = pd.DataFrame(columns=[\"mu\", \"sigma\", \"w\"])\n",
    "        history_record = pd.DataFrame(columns=[\"mu\", \"sigma\", \"w\"])\n",
    "        for i in range(runs):\n",
    "            if self.talk:\n",
    "                print(\"\\nRun number {} over {}.\".format(i, runs))\n",
    "            # reset everything at each run\n",
    "            self.init_params()\n",
    "            initial_record = initial_record.append(pd.DataFrame({\"mu\": self.mu,\n",
    "                                                                 \"sigma\": self.sigma,\n",
    "                                                                 \"w\": self.w}),\n",
    "                                                   ignore_index=True)\n",
    "            self.init_history()\n",
    "            self.split_x()\n",
    "\n",
    "            self.fit(max_iters=max_iters)\n",
    "\n",
    "            for j in range(self.nb_dist):\n",
    "                history_record = history_record.append(pd.DataFrame({\"mu\": [self.history[\"mu\"][-1][j]],\n",
    "                                                                     \"sigma\": [self.history[\"sigma\"][-1][j]],\n",
    "                                                                     \"w\": [self.history[\"w\"][-1][j]]}),\n",
    "                                                       ignore_index=True)\n",
    "\n",
    "        history_record_scaled = (history_record - history_record.min()) / (history_record.max() - history_record.min())\n",
    "        kmeans = KMeans(init=\"random\", n_clusters=self.nb_dist, n_init=10, max_iter=300, random_state=42)\n",
    "        history_record[\"cluster\"] = kmeans.fit_predict(history_record_scaled)\n",
    "        initial_record[\"cluster\"] = history_record[\"cluster\"]\n",
    "        self.initial_record = initial_record.sort_values(by=\"cluster\", ignore_index=True)\n",
    "        self.history_record = history_record.sort_values(by=\"cluster\", ignore_index=True)\n",
    "\n",
    "        clustered_distributions = pd.DataFrame(columns=[\"mu\", \"sigma\", \"w\"])\n",
    "        for i in range(self.nb_dist):\n",
    "            mu = history_record[history_record['cluster'] == i][\"mu\"].mean()\n",
    "            sigma = history_record[history_record['cluster'] == i][\"sigma\"].mean()\n",
    "            w = history_record[history_record['cluster'] == i][\"w\"].mean()\n",
    "            clustered_distributions = clustered_distributions.append(\n",
    "                pd.DataFrame({\"mu\": [mu],\n",
    "                              \"sigma\": [sigma],\n",
    "                              \"w\": [w]}),\n",
    "                ignore_index=True\n",
    "            )\n",
    "        clustered_distributions[\"w\"] /= clustered_distributions[\"w\"].sum()\n",
    "\n",
    "        self.clustered_distributions = clustered_distributions\n",
    "\n",
    "        if self.talk:\n",
    "            print(\"\\n\\n\", \"=\" * 25, \"\\nFinal average parameters :\\n\\tmu :    {}\\n\\tsigma : {}\\n\\tw :     {}\".format(\n",
    "                self.clustered_distributions[\"mu\"].tolist(),\n",
    "                self.clustered_distributions[\"sigma\"].tolist(),\n",
    "                self.clustered_distributions[\"w\"].tolist()))\n",
    "\n",
    "        if plot:\n",
    "            if not plot_title:\n",
    "                plot_title = \"Average fit over {} runs\".format(runs)\n",
    "            self.plot_average(title=plot_title)\n",
    "\n",
    "    ###########################\n",
    "    ### POT FUNCTIONS BELOW ###\n",
    "    ###########################\n",
    "\n",
    "    def plot_average(self, figsize=(20, 6), title=\"specific_plot\", save=True):\n",
    "        abscisse = np.linspace(self.x_all.min(), self.x_all.max(), 1001)\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.suptitle(title)\n",
    "\n",
    "        # hist plots\n",
    "        ax = plt.subplot2grid(shape=(1, 3), loc=(0, 0))\n",
    "        ax.set_title(\"Initial distributions\")\n",
    "        sns.histplot(self.x_all, bins=50, alpha=0.2, color=\"cyan\", stat=\"probability\", ax=ax)\n",
    "\n",
    "        ax0 = plt.subplot2grid(shape=(1, 3), loc=(0, 1))\n",
    "        ax0.set_title(\"All distributions after convergence or max_iters\")\n",
    "        sns.histplot(self.x_all, bins=50, alpha=0.2, color=\"cyan\", stat=\"probability\", ax=ax0)\n",
    "\n",
    "        ax1 = plt.subplot2grid(shape=(1, 3), loc=(0, 2))\n",
    "        ax1.set_title(\"Averaged distributions by {}-means\".format(self.nb_dist))\n",
    "        mu_s = self.clustered_distributions[\"mu\"]\n",
    "        sigma_s = self.clustered_distributions[\"sigma\"]\n",
    "        w_s = self.clustered_distributions[\"w\"]\n",
    "        sns.histplot(self.x_all, bins=50, alpha=0.2, color=\"cyan\", stat=\"probability\", ax=ax1)\n",
    "\n",
    "        # find y_limit\n",
    "        y_lim_top = min(1, ax.set_ylim(auto=True)[1], ax0.set_ylim(auto=True)[1], ax1.set_ylim(auto=True)[1])\n",
    "\n",
    "        # line plots\n",
    "        for j in range(len(self.initial_record)):\n",
    "            ax.plot(abscisse,\n",
    "                    self.initial_record.loc[j, \"w\"] * stats.norm.pdf(abscisse,\n",
    "                                                                     self.initial_record.loc[j, \"mu\"],\n",
    "                                                                     self.initial_record.loc[j, \"sigma\"]),\n",
    "                    color=self.colors[self.initial_record.loc[j, \"cluster\"]])\n",
    "\n",
    "        for j in range(len(self.history_record)):\n",
    "            ax0.plot(abscisse,\n",
    "                     self.history_record.loc[j, \"w\"] * stats.norm.pdf(abscisse,\n",
    "                                                                      self.history_record.loc[j, \"mu\"],\n",
    "                                                                      self.history_record.loc[j, \"sigma\"]),\n",
    "                     color=self.colors[self.history_record.loc[j, \"cluster\"]])\n",
    "\n",
    "        for j in range(self.nb_dist):\n",
    "            ax1.plot(abscisse,\n",
    "                     w_s[j] * stats.norm.pdf(abscisse,\n",
    "                                             mu_s[j],\n",
    "                                             sigma_s[j]),\n",
    "                     color=self.colors[j])\n",
    "\n",
    "        # set y_limit\n",
    "        ax.set_ylim(top=y_lim_top)\n",
    "        ax0.set_ylim(top=y_lim_top)\n",
    "        ax1.set_ylim(top=y_lim_top)\n",
    "\n",
    "        plt.legend([f\"cluster_{i}\" for i in range(self.nb_dist)])\n",
    "\n",
    "        if save:\n",
    "            plt.savefig(\"../../images/1D/\" + title.replace(\" \", \"_\") + \".jpg\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_step(self, step_index, figsize=(10, 7)):\n",
    "        mu = self.history[\"mu\"][step_index]\n",
    "        sigma = self.history[\"sigma\"][step_index]\n",
    "        w = self.history[\"w\"][step_index]\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.title(\"step_index : {}\".format(step_index))\n",
    "        abscisse = np.linspace(self.x_all.min(), self.x_all.max(), 1001)\n",
    "        sns.histplot(self.x_all, bins=50, alpha=0.2, color=\"cyan\", stat=\"probability\")\n",
    "        for j in range(self.nb_dist):\n",
    "            plt.plot(abscisse, w[j] * stats.norm.pdf(abscisse, mu[j], sigma[j]))\n",
    "        plt.show()\n",
    "\n",
    "    def plot_params(self, figsize=(10, 7), title=\"Current parameters\"):\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.title(title)\n",
    "        abscisse = np.linspace(self.x_all.min(), self.x_all.max(), 1001)\n",
    "        sns.histplot(self.x_all, bins=50, alpha=0.2, color=\"cyan\", stat=\"probability\")\n",
    "        for j in range(self.w.shape[0]):\n",
    "            plt.plot(abscisse, self.w[j] * stats.norm.pdf(abscisse, self.mu[j], self.sigma[j]))\n",
    "        plt.show()\n",
    "\n",
    "    def plot_progression(self, figsize=(20, 6), title=\"Expectation Maximization\", save=True):\n",
    "        abscisse = np.linspace(self.x_all.min(), self.x_all.max(), 1001)\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "        ax0 = plt.subplot2grid(shape=(3, 3), loc=(0, 0), rowspan=3)\n",
    "        ax1_0 = plt.subplot2grid(shape=(3, 3), loc=(0, 1))\n",
    "        ax1_1 = plt.subplot2grid(shape=(3, 3), loc=(1, 1))\n",
    "        ax1_2 = plt.subplot2grid(shape=(3, 3), loc=(2, 1))\n",
    "        ax2 = plt.subplot2grid(shape=(3, 3), loc=(0, 2), rowspan=3)\n",
    "\n",
    "        # hist plot\n",
    "        ax0.set_title(\"Initialization\")\n",
    "        mu_init = self.history[\"mu\"][0]\n",
    "        sigma_init = self.history[\"sigma\"][0]\n",
    "        w_init = self.history[\"w\"][0]\n",
    "        sns.histplot(self.x_all, bins=50, alpha=0.2, color=\"cyan\", stat=\"probability\", ax=ax0)\n",
    "\n",
    "        ax2.set_title(\"After {} steps\".format(len(self.history[\"mu\"]) - 1))\n",
    "        sns.histplot(self.x_all, bins=50, alpha=0.2, color=\"cyan\", stat=\"probability\", ax=ax2)\n",
    "\n",
    "        # find y_limit\n",
    "        y_lim_top = min(1, ax0.set_ylim(auto=True)[1], ax2.set_ylim(auto=True)[1])\n",
    "\n",
    "        # line plot\n",
    "        for j in range(self.nb_dist):\n",
    "            ax0.plot(abscisse, w_init[j] * stats.norm.pdf(abscisse, mu_init[j], sigma_init[j]))\n",
    "        for j in range(self.w.shape[0]):\n",
    "            ax2.plot(abscisse, self.w[j] * stats.norm.pdf(abscisse, self.mu[j], self.sigma[j]))\n",
    "\n",
    "        # set y_limit\n",
    "        ax0.set_ylim(top=y_lim_top)\n",
    "        ax2.set_ylim(top=y_lim_top)\n",
    "\n",
    "        ax1_0.set_title(\"parameters\")\n",
    "        for i in range(self.nb_dist):\n",
    "            sns.lineplot(x=np.arange(len(self.history[\"mu\"])),\n",
    "                         y=np.array(self.history[\"mu\"])[:, i],\n",
    "                         ax=ax1_0,\n",
    "                         label=\"{}\".format(i),\n",
    "                         palette=sns.color_palette(\"hls\", 8))\n",
    "        ax1_0.set_ylabel(\"mu\")\n",
    "        ax1_0.set_xticks([])\n",
    "        for i in range(self.nb_dist):\n",
    "            sns.lineplot(x=np.arange(len(self.history[\"sigma\"])),\n",
    "                         y=np.array(self.history[\"sigma\"])[:, i],\n",
    "                         ax=ax1_1,\n",
    "                         label=\"{}\".format(i),\n",
    "                         palette=sns.color_palette(\"hls\", 8))\n",
    "        ax1_1.set_ylabel(\"sigma\")\n",
    "        ax1_1.set_xticks([])\n",
    "        for i in range(self.nb_dist):\n",
    "            sns.lineplot(x=np.arange(len(self.history[\"w\"])),\n",
    "                         y=np.array(self.history[\"w\"])[:, i],\n",
    "                         ax=ax1_2,\n",
    "                         label=\"{}\".format(i),\n",
    "                         palette=sns.color_palette(\"hls\", 8))\n",
    "        ax1_2.set_ylabel(\"w\")\n",
    "        ax1_2.set_xlabel(\"steps\")\n",
    "        x_ticks = [i for i in range(len(self.history[\"w\"]))]\n",
    "        step = len(x_ticks) // 20 + 1\n",
    "        x_ticks = x_ticks[::step]\n",
    "        ax1_2.set_xticks(x_ticks)\n",
    "\n",
    "        plt.suptitle(title, fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        if save:\n",
    "            plt.savefig(\"../../images/1D/\" + title.replace(\" \", \"_\") + \".jpg\")\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for col in ['wind_speed', 'temperature', 'humidity', 'dew_point', 'current_precipitations']:\n",
    "    print(\"\\n\\n\", \"=\" * 50, sep=\"\")\n",
    "    print(\"\\n\\t\", col)\n",
    "    print(\"\\n\", \"=\" * 50, \"\\n\\n\", sep=\"\")\n",
    "    for k in range(2, 5):\n",
    "        em = EM_1D(x=df[col].to_numpy(), nb_dist=k, split_ratio=0.01, threshold=0.001, talk=True)\n",
    "        t = time.time()\n",
    "        try:\n",
    "            em.average_fit(runs=5, max_iters=1000, plot=True,\n",
    "                           plot_title=\"Expectation Maximization - {} - fit {} normal distribution(s) - Average fit over 5 runs.\".format(\n",
    "                               col, k))\n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "        finally:\n",
    "            print(\"elapsed : {:.2f} s.\".format(time.time() - t))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for col in ['wind_speed', 'temperature', 'humidity', 'dew_point', 'current_precipitations']:\n",
    "    print(\"\\n\\n\", \"=\" * 50, sep=\"\")\n",
    "    print(\"\\n\\t\", col)\n",
    "    print(\"\\n\", \"=\" * 50, \"\\n\\n\", sep=\"\")\n",
    "    for k in range(1, 5):\n",
    "        em = EM_1D(x=df[col].to_numpy(), nb_dist=k, split_ratio=0.01, threshold=0.001, talk=True)\n",
    "        t = time.time()\n",
    "        try :\n",
    "            em.fit(max_iters=1000)\n",
    "            em.plot_progression(title=\"Expectation Maximization - {} - fit {} normal distribution(s)\".format(col, k))\n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "        finally:\n",
    "            print(\"elapsed : {:.2f} s.\".format(time.time() - t))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 dimension"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "source : https://towardsdatascience.com/implement-expectation-maximization-em-algorithm-in-python-from-scratch-f1278d1b9137"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# source : https://github.com/matplotlib/matplotlib/blob/81e8154dbba54ac1607b21b22984cabf7a6598fa/lib/matplotlib/mlab.py#L1866\n",
    "def bivariate_normal(X, Y,\n",
    "                     sigmax=1.0,\n",
    "                     sigmay=1.0,\n",
    "                     mux=0.0,\n",
    "                     muy=0.0,\n",
    "                     sigmaxy=0.0):\n",
    "    \"\"\"\n",
    "    Bivariate Gaussian distribution for equal shape *X*, *Y*.\n",
    "    See `bivariate normal\n",
    "    <http://mathworld.wolfram.com/BivariateNormalDistribution.html>`_\n",
    "    at mathworld.\n",
    "\n",
    "    **Depreciated from matplotlib.**\n",
    "    \"\"\"\n",
    "    Xmu = X - mux\n",
    "    Ymu = Y - muy\n",
    "\n",
    "    rho = sigmaxy / (sigmax * sigmay)\n",
    "    z = Xmu ** 2 / sigmax ** 2 + Ymu ** 2 / sigmay ** 2 - 2 * rho * Xmu * Ymu / (sigmax * sigmay)\n",
    "    denom = 2 * np.pi * sigmax * sigmay * np.sqrt(1 - rho ** 2)\n",
    "    return np.exp(-z / (2 * (1 - rho ** 2))) / denom\n",
    "\n",
    "\n",
    "class EM_2D():\n",
    "    def __init__(self, x: np.ndarray, nb_dist=2, split_ratio=0.1, threshold=1e-10, minimum_sigma=1e-5, talk=False):\n",
    "        self.talk = talk  # whether to display information or not\n",
    "        self.threshold = threshold  # threshold ratio to trigger stop_fitting\n",
    "        self.minimum_sigma = minimum_sigma  # to avoid sigma being 0\n",
    "        self.stop_fitting = False  # stop fitting if maximum iterations reached or threshold passed\n",
    "        self.nb_dist = nb_dist  # number of distributions to fit\n",
    "\n",
    "        self.split_ratio = split_ratio  # part of x to keep to initialize the parameters\n",
    "        self.x_all = x  # backup of whole x data\n",
    "        self.idx_sample = None  # index of x_sample for initialization\n",
    "        self.x_sample = None  # sample for initialization\n",
    "        self.x = None  # training part of x\n",
    "        self.split_x()  # fill x_sample, idx_sample and x\n",
    "\n",
    "        self.average_by_dist_log_likelihood_record = []  # log_likelihood computed in e_step()\n",
    "        self.average_log_likelihood_record = []  # log_likelihood computed in e_step()\n",
    "        self.heuristics = None  # heuristics computed in e_step()\n",
    "\n",
    "        self.mu = None  # average\n",
    "        self.sigma = None  # standard deviation\n",
    "        self.w = None  # weights\n",
    "        self.init_params()  # initialize the above\n",
    "\n",
    "        self.history = None  # history\n",
    "        self.init_history()  # initialize history\n",
    "\n",
    "        self.r = None  # declare r to anticipate fit()\n",
    "\n",
    "        self.initial_record = None  # declare variable, used in average_fit()\n",
    "        self.history_record = None  # declare variable, used in average_fit()\n",
    "        self.clustered_distributions = None  # declare variable, used in average_fit()\n",
    "\n",
    "        self.colors = [\"blue\", \"red\", \"orange\", \"green\", \"magenta\"]\n",
    "\n",
    "    def split_x(self):\n",
    "        self.idx_sample = rng.choice(np.arange(self.x_all.shape[0]),\n",
    "                                     replace=False,\n",
    "                                     size=int(self.x_all.shape[0] * self.split_ratio))\n",
    "        self.x_sample = self.x_all[self.idx_sample]\n",
    "        self.x = np.delete(self.x_all, self.idx_sample, axis=0)\n",
    "\n",
    "    def init_params(self):\n",
    "        mu = []\n",
    "        for _ in range(self.nb_dist):\n",
    "            mu.append(np.array(\n",
    "                [rng.normal(loc=np.mean(self.x_sample[:, 0]),\n",
    "                            scale=5),\n",
    "                 rng.normal(loc=np.mean(self.x_sample[:, 1]),\n",
    "                            scale=5)]))\n",
    "\n",
    "        sigma = []\n",
    "        for _ in range(self.nb_dist):\n",
    "            s = np.zeros(shape=(2, 2))\n",
    "            s[0, 0] = np.abs(rng.normal(loc=np.sqrt(np.var(self.x_sample[:, 0])),\n",
    "                                        scale=2))\n",
    "            s[1, 1] = np.abs(rng.normal(loc=np.sqrt(np.var(self.x_sample[:, 1])),\n",
    "                                        scale=2))\n",
    "            sigma.append(s)\n",
    "        w = np.abs(rng.normal(loc=1,\n",
    "                              scale=0.2,\n",
    "                              size=self.nb_dist))\n",
    "        w /= w.sum()\n",
    "        if self.talk:\n",
    "            print(\"Initial parameters :\")\n",
    "            print(\"\\t - mu :    {}\".format(np.round(mu, 2)))\n",
    "            print(\"\\t - sigma : {}\".format(np.round(sigma, 2)))\n",
    "            print(\"\\t - w :     {}\".format(np.round(w, 2)))\n",
    "        self.mu, self.sigma, self.w = mu, sigma, w\n",
    "\n",
    "    def init_history(self):\n",
    "        history = {\"mu\": [self.mu],\n",
    "                   \"sigma\": [self.sigma],\n",
    "                   \"w\": [self.w]}\n",
    "        self.history = history\n",
    "\n",
    "    def update_h(self):\n",
    "        self.history[\"mu\"].append(self.mu)\n",
    "        self.history[\"sigma\"].append(self.sigma)\n",
    "        self.history[\"w\"].append(self.w)\n",
    "\n",
    "    def e_step(self):\n",
    "        np.log([stats.multivariate_normal.pdf(self.x,\n",
    "                                              self.mu[i],\n",
    "                                              self.sigma[i])\n",
    "                for i in range(self.nb_dist)])\n",
    "        log_p_y_x = np.log([self.w[i] for i in range(self.nb_dist)])[np.newaxis, ...] +\\\n",
    "                    np.log([stats.multivariate_normal.pdf(self.x,\n",
    "                                                          self.mu[i],\n",
    "                                                          self.sigma[i])\n",
    "                            for i in range(self.nb_dist)]).T\n",
    "        log_p_y_x_norm = logsumexp(log_p_y_x, axis=1)\n",
    "\n",
    "        self.average_by_dist_log_likelihood_record.append(log_p_y_x.mean(axis=0))\n",
    "        self.average_log_likelihood_record.append(log_p_y_x_norm.mean())  # log_likelyhood\n",
    "        self.heuristics = np.exp(log_p_y_x - log_p_y_x_norm[..., np.newaxis])\n",
    "\n",
    "    def m_step(self):\n",
    "        total_count = self.x.shape[0]\n",
    "\n",
    "        sum_heuristic = np.sum(self.heuristics, axis=0)\n",
    "\n",
    "        w = (sum_heuristic / total_count)\n",
    "        mu = []\n",
    "        sigma = []\n",
    "        for i in range(self.nb_dist):\n",
    "            mu.append((self.heuristics[:, i][..., np.newaxis].T.dot(self.x) / sum_heuristic[i]).flatten())\n",
    "            diff = self.x - mu[-1]\n",
    "            sigma.append(diff.T.dot(diff * self.heuristics[:, i][..., np.newaxis]) / sum_heuristic[i])\n",
    "            if np.linalg.det(sigma[-1]) == 0:\n",
    "                print(\n",
    "                    \"WARNING : det(sigma) == 0, add minimum_sigma = {}\".format(self.minimum_sigma))\n",
    "                sigma[-1] += self.minimum_sigma\n",
    "            if sigma[-1][0,0] == 0:\n",
    "                print(\"WARNING : sigma[0,0] == 0, add minimum_sigma = {}\".format(self.minimum_sigma))\n",
    "                sigma[-1][0,0] += self.minimum_sigma\n",
    "            if sigma[-1][1,1] == 0:\n",
    "                print(\"WARNING : sigma[1,1] == 0, add minimum_sigma = {}\".format(self.minimum_sigma))\n",
    "                sigma[-1][1,1] += self.minimum_sigma\n",
    "\n",
    "        self.w = w\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def fit(self, max_iters=100):\n",
    "        self.stop_fitting = False\n",
    "        for i in range(max_iters):\n",
    "            if self.talk and i % int(max_iters // 100 + 1) == 0:\n",
    "                print(\"{} %\".format(int(i / max_iters * 100)).rjust(5), end=\"\\r\")\n",
    "\n",
    "            self.e_step()\n",
    "            self.m_step()\n",
    "            self.update_h()\n",
    "\n",
    "            if len(self.average_log_likelihood_record) > 2 and\\\n",
    "                    np.abs(self.average_log_likelihood_record[-1] -\\\n",
    "                           self.average_log_likelihood_record[-2]) < self.threshold:\n",
    "                self.stop_fitting = True\n",
    "                break\n",
    "\n",
    "        if self.talk:\n",
    "            print(\"\\n\")\n",
    "            if self.stop_fitting:\n",
    "                print(\"Threshold reached, less than {} % difference.\".format(self.threshold * 100))\n",
    "            else:\n",
    "                print(\"100 %\")\n",
    "            print(\"Final parameters :\\n\\tmu :    {}\\n\\tsigma : {}\\n\\tw :     {}\".format(self.history[\"mu\"][-1],\n",
    "                                                                                        self.history[\"sigma\"][-1],\n",
    "                                                                                        self.history[\"w\"][-1]))\n",
    "\n",
    "    def average_fit(self, runs=3, max_iters=100, plot=True, plot_title=\"\"):\n",
    "        \"\"\"\n",
    "        to avoid initialization issues, average over [runs] fit() and different initializations.\n",
    "        :param plot_title: title of the plot of plot\n",
    "        :param runs: number of fit() to execute\n",
    "        :param max_iters: maximum number of iterations for each fit()\n",
    "        :param plot: plot the final result, average of all fit()\n",
    "\n",
    "        updates to history to every parameters fo every fit() (for plotting purpose) and parameters to average of every run.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"not implemented yet.\")\n",
    "\n",
    "    ###########################\n",
    "    ### POT FUNCTIONS BELOW ###\n",
    "    ###########################\n",
    "\n",
    "    def get_contour_parameters(self):\n",
    "        # source : https://stackoverflow.com/questions/37890550/python-plotting-percentile-contour-lines-of-a-probability-distribution\n",
    "        min_x = self.x_all[:, 0].min()\n",
    "        max_x = self.x_all[:, 0].max()\n",
    "        min_y = self.x_all[:, 1].min()\n",
    "        max_y = self.x_all[:, 1].max()\n",
    "        extent = [min_x, max_x, min_y, max_y]\n",
    "\n",
    "        X, Y = np.mgrid[min_x:max_x:200j, min_y:max_y:200j]\n",
    "\n",
    "        for i in range(self.nb_dist):\n",
    "            z = self.w[i] * bivariate_normal(X, Y,\n",
    "                                             mux=self.mu[i][0],\n",
    "                                             muy=self.mu[i][1],\n",
    "                                             sigmax=self.sigma[i][0, 0],\n",
    "                                             sigmay=self.sigma[i][1, 1],\n",
    "                                             sigmaxy=self.sigma[i][1, 0])\n",
    "            z = z / z.sum()\n",
    "            n = 1000\n",
    "            t = np.linspace(0, z.max(), n)\n",
    "            integral = ((z >= t[:, None, None]) * z).sum(axis=(1, 2))\n",
    "\n",
    "            f = interpolate.interp1d(integral, t)\n",
    "            t_contours = f(np.array([0.9, 0.7, 0.5, 0.3, 0.1]) / 5)\n",
    "            yield z, t_contours, extent\n",
    "\n",
    "    def plot_2D(self, cols=(\"\", \"\"), scatter=False, contour=True, progression=True, height=10,\n",
    "                title=\"Expectation Maximization 2D\",\n",
    "                save=False, show=True):\n",
    "        h = sns.jointplot(x=self.x_all[:, 0],\n",
    "                          y=self.x_all[:, 1],\n",
    "                          kind=\"hex\",\n",
    "                          marginal_kws={\"bins\": 100},\n",
    "                          height=height)\n",
    "        h.set_axis_labels(*cols)\n",
    "        h.figure.tight_layout()\n",
    "\n",
    "        if scatter:\n",
    "            for i in range(self.nb_dist):\n",
    "                norm = rng.multivariate_normal(self.mu[i], self.sigma[i], size=(2, 10000))[0]\n",
    "                sns.scatterplot(x=norm[:, 0], y=norm[:, 1], alpha=0.1, color=self.colors[i])\n",
    "\n",
    "        if contour:\n",
    "            generator_contour = self.get_contour_parameters()\n",
    "            for i in range(self.nb_dist):\n",
    "                z, t_contours, extent = next(generator_contour)\n",
    "                # plt.imshow(z.T, origin='lower', extent=[min_x,max_x,min_y,max_y], cmap=\"gray\")\n",
    "                plt.contour(z.T, t_contours, extent=extent, colors=self.colors[i])\n",
    "\n",
    "        if progression:\n",
    "            line_mu = {i: [] for i in range(self.nb_dist)}\n",
    "            for i in range(self.nb_dist):\n",
    "                for j in range(len(self.history[\"mu\"])):\n",
    "                    line_mu[i].append(self.history[\"mu\"][j][i])\n",
    "                line_mu[i] = np.array(line_mu[i])\n",
    "                plt.plot(line_mu[i][:, 0],\n",
    "                         line_mu[i][:, 1],\n",
    "                         marker=\"o\",\n",
    "                         color=\"magenta\",\n",
    "                         markersize=2,\n",
    "                         linewidth=1)\n",
    "\n",
    "        if scatter or contour or progression:\n",
    "            for i in range(self.nb_dist):\n",
    "                plt.text(x=self.mu[i][0] - 1,\n",
    "                         y=self.mu[i][1],\n",
    "                         s=\"w:\" + str(round(self.w[i], 2)),\n",
    "                         color=self.colors[i],\n",
    "                         bbox=dict(facecolor='white', alpha=0.5),\n",
    "                         )\n",
    "\n",
    "        plt.title(title, y=.97)\n",
    "        if save:\n",
    "            plt.savefig(\"../../images/2D/\" + title.replace(\" \", \"_\") + \".jpg\")\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else :\n",
    "            plt.close(h)\n",
    "\n",
    "\n",
    "    def plot_likelihood(self, figsize=(10, 5), title=\"likelihood\", save=False, show=True):\n",
    "        plt.figure(figsize=figsize)\n",
    "        log_likelihood = np.array(self.average_by_dist_log_likelihood_record)\n",
    "        for i in range(self.nb_dist):\n",
    "            sns.lineplot(x=np.arange(0, log_likelihood.shape[0]),\n",
    "                         y=log_likelihood[:, i],\n",
    "                         color=self.colors[i])\n",
    "        sns.lineplot(x=np.arange(0, len(self.average_log_likelihood_record)),\n",
    "                     y=self.average_log_likelihood_record,\n",
    "                     color=\"black\")\n",
    "        plt.legend([\"distrib. \" + str(i) for i in range(self.nb_dist)] + [\"Global\"])\n",
    "        plt.xlabel(\"steps\")\n",
    "        plt.ylabel(\"log_likelihood\")\n",
    "        plt.title(title)\n",
    "        if save:\n",
    "            plt.savefig(\"../../images/2D/\" + title.replace(\" \", \"_\") + \".jpg\")\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else :\n",
    "            plt.cls()\n",
    "\n",
    "    def plot_original(self, cols=(\"\", \"\"), title=\"Original\", save=False, show=True):\n",
    "        h = sns.jointplot(x=self.x_all[:, 0],\n",
    "                          y=self.x_all[:, 1],\n",
    "                          kind=\"hex\",\n",
    "                          marginal_kws={\"bins\": 100},\n",
    "                          height=10)\n",
    "        h.set_axis_labels(*cols)\n",
    "        h.figure.tight_layout()\n",
    "        plt.title(title, y=.97)\n",
    "        if save:\n",
    "            plt.savefig(\"../../images/2D/\" + title.replace(\" \", \"_\") + \".jpg\")\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else :\n",
    "            plt.close(h)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns = ['wind_speed', 'temperature', 'humidity', 'dew_point', 'current_precipitations']\n",
    "show = False\n",
    "for i in range(len(columns)):\n",
    "    for j in range(i + 1, len(columns)):\n",
    "        plot_original = True\n",
    "        col1 = columns[i]\n",
    "        col2 = columns[j]\n",
    "        for k in range(2, 5):\n",
    "            for run in range(1, 4):\n",
    "                t=time.time()\n",
    "                title = f\"{run}/Expectation Maximization 2D - {col1} and {col2}\"\n",
    "                em2 = EM_2D(x=df[[col1, col2]].to_numpy(), nb_dist=k)\n",
    "                if plot_original:\n",
    "                    #plot original distribution\n",
    "                    em2.plot_original(title=title + \" - original\", cols=[col1, col2], save=True, show=False)\n",
    "                    plot_original = False\n",
    "                try :\n",
    "                    #fit\n",
    "                    em2.fit(max_iters=300)\n",
    "                    #plot fit\n",
    "                    em2.plot_2D(title=title + f\" - fit {k} normal distributions\", cols=[col1, col2], scatter=True,\n",
    "                                contour=True, progression=True, save=True, show=False)\n",
    "                    #plot likelihood\n",
    "                    em2.plot_likelihood(title=title + f\" - fit {k} normal distributions - likelihood\", save=True,\n",
    "                                        show=False)\n",
    "                except Exception:\n",
    "                    traceback.print_exc()\n",
    "                finally:\n",
    "                    print(\"elapsed : {:.2f} s.\".format(time.time() - t))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from jax import numpy as jnp\n",
    "from jax import ops, random\n",
    "from jax.scipy.special import expit\n",
    "\n",
    "import numpyro\n",
    "from numpyro import distributions as dist\n",
    "from numpyro.distributions import constraints\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "from sklearn.model_selection import train_test_split\n",
    "from icecream import ic\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "import random as rd\n",
    "import time\n",
    "def m_mape(y_true, y_predict):\n",
    "    n = len(y_true)\n",
    "    At = np.array(y_true) + 1\n",
    "    Ft = np.array(y_predict) + 1\n",
    "\n",
    "    res = ((100/n)*(np.sum(np.abs((Ft-At)/At))))\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://num.pyro.ai/en/latest/tutorials/bayesian_imputation.html?highlight=imputation\n",
    "https://num.pyro.ai/en/latest/utilities.html?highlight=Predictive%20regression#numpyro.infer.util.Predictive\n",
    "https://num.pyro.ai/en/latest/tutorials/bayesian_regression.html?highlight=Predictive%20regression#Bayesian-Regression-Using-NumPyro (Posterior predictive)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "   station_id  year  month  day  latitude  longitude  altitude  \\\n0    14066001  2016      1    1    49.334     -0.431         2   \n1    14066001  2016      1    2    49.334     -0.431         2   \n2    14066001  2016      1    3    49.334     -0.431         2   \n3    14066001  2016      1    4    49.334     -0.431         2   \n4    14066001  2016      1    5    49.334     -0.431         2   \n\n   wind_direction  wind_speed  temperature   humidity  dew_point  \\\n0       146.50000    3.913750    280.33374  88.591670  278.51460   \n1       205.62500    8.041250    282.93668  82.300000  279.99750   \n2       195.25000    5.430417    281.10165  86.604164  278.99750   \n3       212.66667    6.715417    281.05500  80.645836  277.90082   \n4       205.04167    5.957083    281.25583  82.750000  278.48416   \n\n   precipitations  ground_truth  \n0             0.2           3.4  \n1             3.4          11.7  \n2            11.7           0.6  \n3             0.6           0.4  \n4             0.4           3.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>station_id</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>altitude</th>\n      <th>wind_direction</th>\n      <th>wind_speed</th>\n      <th>temperature</th>\n      <th>humidity</th>\n      <th>dew_point</th>\n      <th>precipitations</th>\n      <th>ground_truth</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14066001</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>1</td>\n      <td>49.334</td>\n      <td>-0.431</td>\n      <td>2</td>\n      <td>146.50000</td>\n      <td>3.913750</td>\n      <td>280.33374</td>\n      <td>88.591670</td>\n      <td>278.51460</td>\n      <td>0.2</td>\n      <td>3.4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14066001</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>2</td>\n      <td>49.334</td>\n      <td>-0.431</td>\n      <td>2</td>\n      <td>205.62500</td>\n      <td>8.041250</td>\n      <td>282.93668</td>\n      <td>82.300000</td>\n      <td>279.99750</td>\n      <td>3.4</td>\n      <td>11.7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14066001</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>3</td>\n      <td>49.334</td>\n      <td>-0.431</td>\n      <td>2</td>\n      <td>195.25000</td>\n      <td>5.430417</td>\n      <td>281.10165</td>\n      <td>86.604164</td>\n      <td>278.99750</td>\n      <td>11.7</td>\n      <td>0.6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14066001</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>4</td>\n      <td>49.334</td>\n      <td>-0.431</td>\n      <td>2</td>\n      <td>212.66667</td>\n      <td>6.715417</td>\n      <td>281.05500</td>\n      <td>80.645836</td>\n      <td>277.90082</td>\n      <td>0.6</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14066001</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>5</td>\n      <td>49.334</td>\n      <td>-0.431</td>\n      <td>2</td>\n      <td>205.04167</td>\n      <td>5.957083</td>\n      <td>281.25583</td>\n      <td>82.750000</td>\n      <td>278.48416</td>\n      <td>0.4</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"../data/X_station_day.csv\")\n",
    "dataset.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between  temperature and humidity\n",
      "Pearson's correlation: -0.355\n",
      "Spearman's correlation: -0.401\n",
      "Correlation between  temperature and dew_point\n",
      "Pearson's correlation: 0.935\n",
      "Spearman's correlation: 0.924\n",
      "Correlation between  humidity and precipitations\n",
      "Pearson's correlation: 0.426\n",
      "Spearman's correlation: 0.257\n"
     ]
    }
   ],
   "source": [
    "columns = dataset.columns.tolist()\n",
    "for i in range(len(columns)):\n",
    "    for j in range(i, len(columns)):\n",
    "        if i != j:\n",
    "            spearman_correlation = dataset[columns[i]].corr(dataset[columns[j]], method='spearman')\n",
    "            pearson_correlation = dataset[columns[i]].corr(dataset[columns[j]], method='pearson')\n",
    "            if max(np.abs(spearman_correlation), np.abs(pearson_correlation)) > 0.4 :\n",
    "                print('Correlation between ', columns[i], 'and', columns[j])\n",
    "                print('Pearson\\'s correlation: %.3f' % spearman_correlation)\n",
    "                print('Spearman\\'s correlation: %.3f' % pearson_correlation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# General functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_normalization_infos(*x_s, columns):\n",
    "    normalization_infos = pd.DataFrame(data=[[1000 for _ in range(len(columns))],[0 for _ in range(len(columns))]],\n",
    "                                       index=[\"min\",\"max\"],\n",
    "                                       columns=columns)\n",
    "    for x in x_s :\n",
    "        for col in columns:\n",
    "            min_value = min(normalization_infos[col][\"min\"], x[col].min())\n",
    "            max_value = max(normalization_infos[col][\"max\"], x[col].max())\n",
    "            normalization_infos[col] = [min_value, max_value]\n",
    "\n",
    "    normalization_infos.loc[\"spread\"] = normalization_infos.apply(lambda c : c[\"max\"] - c[\"min\"], axis=0)\n",
    "\n",
    "    return normalization_infos\n",
    "\n",
    "\n",
    "def normalize(x : pd.DataFrame, normalization_infos : pd.DataFrame):\n",
    "    for col in x.columns:\n",
    "        x[col] = (x[col] - normalization_infos[col][\"min\"])/normalization_infos[col][\"spread\"]\n",
    "    return x\n",
    "\n",
    "def de_normalize(x : pd.DataFrame, normalization_infos : pd.DataFrame):\n",
    "    for col in x.columns:\n",
    "        x[col] = x[col] * normalization_infos[col][\"spread\"] + normalization_infos[col][\"min\"]\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_nans(dataset, columns, ratio_nan):\n",
    "    for col in columns:\n",
    "        random_vec = np.random.random(dataset[col].shape) < 1 - ratio_nan\n",
    "        dataset[col] = dataset[col].where(random_vec, other=np.nan)\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def model_ground_truth(\n",
    "        latitude, longitude, altitude, wind_direction, wind_speed, temperature, humidity, dew_point, precipitations, mu=None, sigma=None, ground_truth=None,\n",
    "        nan_columns = None\n",
    "):\n",
    "    lat, long, alt, w_d, w_s, temp, hum, d_pt, prec = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    default = numpyro.sample(\"default\", dist.Normal(0.0, 0.2))\n",
    "    if latitude is not None:\n",
    "        bayes_latitude = numpyro.sample('bayes_latitude', dist.Normal(0, 1))\n",
    "        lat = bayes_latitude * latitude\n",
    "    if longitude is not None:\n",
    "        bayes_longitude = numpyro.sample('bayes_longitude', dist.Normal(0, 1))\n",
    "        long = bayes_longitude * longitude\n",
    "    if altitude is not None:\n",
    "        bayes_altitude = numpyro.sample('bayes_altitude', dist.Normal(0, 1))\n",
    "        alt = bayes_altitude * altitude\n",
    "\n",
    "    if 'wind_direction' in nan_columns:\n",
    "        wd_mu = numpyro.sample(\"wd_mu\", dist.Normal(mu['wind_direction'], 0.2))\n",
    "        wd_sigma = numpyro.sample(\"wd_sigma\", dist.Normal(sigma['wind_direction'], 0.2))\n",
    "\n",
    "        wind_direction_nanidx = np.array(np.isnan(wind_direction).astype(int)).nonzero()[0]\n",
    "        wd_impute = numpyro.sample(\"wd_impute\", dist.Normal(wd_mu, wd_sigma)\n",
    "                                            .expand((len(wind_direction_nanidx),))\n",
    "                                            .mask(False))\n",
    "\n",
    "        wind_direction = ops.index_update(wind_direction, wind_direction_nanidx, wd_impute)\n",
    "\n",
    "        numpyro.sample(\"latent_wind_direction\", dist.Normal(mu['wind_direction'], sigma['wind_direction']), obs=wind_direction)\n",
    "        bayes_wind_direction = numpyro.sample(\"bayes_wind_direction\", dist.Normal(0, 1))\n",
    "        w_d = bayes_wind_direction * wind_direction\n",
    "    else:\n",
    "        if wind_direction is not None:\n",
    "            bayes_wind_direction = numpyro.sample('bayes_wind_direction', dist.Normal(0, 1))\n",
    "            w_d = bayes_wind_direction * wind_direction\n",
    "\n",
    "    if 'wind_speed' in nan_columns:\n",
    "        ws_mu = numpyro.sample(\"ws_mu\", dist.Normal(mu['wind_speed'], 0.2))\n",
    "        ws_sigma = numpyro.sample(\"ws_sigma\", dist.Normal(sigma['wind_speed'], 0.2))\n",
    "\n",
    "        wind_speed_nanidx = np.array(np.isnan(wind_speed).astype(int)).nonzero()[0]\n",
    "        ws_impute = numpyro.sample(\"ws_impute\", dist.Normal(ws_mu, ws_sigma)\n",
    "                                   .expand((len(wind_speed_nanidx),))\n",
    "                                   .mask(False))\n",
    "\n",
    "        wind_speed = ops.index_update(wind_speed, wind_speed_nanidx, ws_impute)\n",
    "\n",
    "        numpyro.sample(\"latent_wind_speed\", dist.Normal(mu['wind_speed'], sigma['wind_speed']), obs=wind_speed)\n",
    "        bayes_wind_speed = numpyro.sample(\"bayes_wind_speed\", dist.Normal(0, 1))\n",
    "        w_s = bayes_wind_speed * wind_speed\n",
    "    else:\n",
    "        if wind_speed is not None:\n",
    "            bayes_wind_speed = numpyro.sample('bayes_wind_speed', dist.Normal(0, 1))\n",
    "            w_s = bayes_wind_speed * wind_speed\n",
    "\n",
    "    if 'temperature' in nan_columns:\n",
    "        temp_mu = numpyro.sample(\"temp_mu\", dist.Normal(mu['temperature'], 0.2))\n",
    "        temp_sigma = numpyro.sample(\"temp_sigma\", dist.Normal(sigma['temperature'], 0.2))\n",
    "\n",
    "        temperature_nanidx = np.array(np.isnan(temperature).astype(int)).nonzero()[0]\n",
    "        temperature_impute = numpyro.sample(\"temperature_impute\", dist.Normal(temp_mu, temp_sigma)\n",
    "                                         .expand((len(temperature_nanidx),))\n",
    "                                         .mask(False))\n",
    "\n",
    "        temperature = ops.index_update(temperature, temperature_nanidx, temperature_impute)\n",
    "\n",
    "        numpyro.sample(\"latent_temperature\", dist.Normal(mu['temperature'], sigma['temperature']), obs=temperature)\n",
    "        bayes_temperature = numpyro.sample(\"bayes_temperature\", dist.Normal(0, 1))\n",
    "        temp = bayes_temperature * temperature\n",
    "    else:\n",
    "        if temperature is not None:\n",
    "            bayes_temperature = numpyro.sample('bayes_temperature', dist.Normal(0, 1))\n",
    "            temp = bayes_temperature * temperature\n",
    "\n",
    "    if 'humidity' in nan_columns:\n",
    "        hum_mu = numpyro.sample(\"hum_mu\", dist.Normal(mu['humidity'], 0.2))\n",
    "        hum_sigma = numpyro.sample(\"hum_sigma\", dist.Normal(sigma['humidity'], 0.2))\n",
    "\n",
    "        humidity_nanidx = np.array(np.isnan(humidity).astype(int)).nonzero()[0]\n",
    "        humidity_impute = numpyro.sample(\"humidity_impute\", dist.Normal(hum_mu, hum_sigma)\n",
    "                                          .expand((len(humidity_nanidx),))\n",
    "                                          .mask(False))\n",
    "\n",
    "        humidity = ops.index_update(humidity, humidity_nanidx, humidity_impute)\n",
    "\n",
    "        numpyro.sample(\"latent_humidity\", dist.Normal(mu['humidity'], sigma['humidity']), obs=humidity)\n",
    "        bayes_humidity = numpyro.sample('bayes_humidity', dist.Normal(0, 1))\n",
    "        hum = bayes_humidity * humidity\n",
    "    else:\n",
    "        if humidity is not None:\n",
    "            bayes_humidity = numpyro.sample('bayes_humidity', dist.Normal(0, 1))\n",
    "            hum = bayes_humidity * humidity\n",
    "\n",
    "    if 'dew_point' in nan_columns:\n",
    "        dew_point_mu = numpyro.sample(\"dew_point_mu\", dist.Normal(mu['dew_point'], 0.2))\n",
    "        dew_point_sigma = numpyro.sample(\"dew_point_sigma\", dist.Normal(sigma['dew_point'], 0.2))\n",
    "\n",
    "        dew_point_nanidx = np.array(np.isnan(dew_point).astype(int)).nonzero()[0]\n",
    "        dew_point_impute = numpyro.sample(\"dew_point_impute\", dist.Normal(dew_point_mu, dew_point_sigma)\n",
    "                                               .expand((len(dew_point_nanidx),))\n",
    "\n",
    "                                               .mask(False))\n",
    "\n",
    "        dew_point = ops.index_update(dew_point, dew_point_nanidx, dew_point_impute)\n",
    "\n",
    "        numpyro.sample(\"latent_dew_point\", dist.Normal(mu['dew_point'], sigma['dew_point']), obs=dew_point)\n",
    "        bayes_dew_point = numpyro.sample('bayes_dew_point', dist.Normal(0, 1))\n",
    "        d_pt = bayes_dew_point * dew_point\n",
    "    else:\n",
    "        if dew_point is not None:\n",
    "            bayes_dew_point = numpyro.sample('bayes_dew_point', dist.Normal(0, 1))\n",
    "            d_pt = bayes_dew_point * dew_point\n",
    "    if 'precipitations' in nan_columns:\n",
    "        precipitations_mu = numpyro.sample(\"precipitations_mu\", dist.Normal(mu['precipitations'], 0.2))\n",
    "        precipitations_sigma = numpyro.sample(\"precipitations_sigma\", dist.Normal(sigma['precipitations'], 0.2))\n",
    "\n",
    "        precipitations_nanidx = np.array(np.isnan(precipitations).astype(int)).nonzero()[0]\n",
    "        precipitations_impute = numpyro.sample(\"precipitations_impute\", dist.Normal(precipitations_mu, precipitations_sigma)\n",
    "                                            .expand((len(precipitations_nanidx),))\n",
    "                                            .mask(False))\n",
    "\n",
    "        precipitations = ops.index_update(precipitations, precipitations_nanidx, precipitations_impute)\n",
    "\n",
    "        numpyro.sample(\"latent_precipitations\", dist.Normal(mu['precipitations'], sigma['precipitations']), obs=precipitations)\n",
    "        bayes_precipitations = numpyro.sample('bayes_precipitations', dist.Normal(0, 1))\n",
    "        prec = bayes_precipitations * precipitations\n",
    "    else:\n",
    "        if precipitations is not None:\n",
    "            bayes_precipitations = numpyro.sample('bayes_precipitations', dist.Normal(0, 1))\n",
    "            prec = bayes_precipitations * precipitations\n",
    "\n",
    "    sigma_model = numpyro.sample(\"sigma\", dist.Exponential(1.0))\n",
    "    mu_model = default + lat + long + alt + w_d + w_s + temp + hum + d_pt + prec\n",
    "    # print(\"sigma\", sigma_model, \"mu\", mu_model)\n",
    "    numpyro.sample(\"ground_truth\", dist.Normal(mu_model, sigma_model), obs=ground_truth)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data fully provided"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def get_data(normalization = True):\n",
    "    dataset = pd.read_csv(\"../data/X_station_day.csv\")\n",
    "    del dataset['station_id']\n",
    "    ground_truth = dataset.ground_truth.values\n",
    "    del dataset['ground_truth']\n",
    "\n",
    "    columns = dataset.columns.tolist()\n",
    "    print(columns)\n",
    "\n",
    "    if normalization:\n",
    "        normalisation_infos = get_normalization_infos(dataset, columns=columns)\n",
    "        dataset = normalize(dataset, normalisation_infos)\n",
    "\n",
    "    data = dict(\n",
    "        latitude = dataset.latitude.values,\n",
    "        longitude = dataset.longitude.values,\n",
    "        altitude = dataset.altitude.values,\n",
    "        wind_direction = dataset.wind_direction.values,\n",
    "        wind_speed = dataset.wind_speed.values,\n",
    "        temperature = dataset.temperature.values,\n",
    "        humidity = dataset.humidity.values,\n",
    "        dew_point = dataset.dew_point.values,\n",
    "        precipitations = dataset.precipitations.values,\n",
    "    )\n",
    "\n",
    "    mu_col = dict()\n",
    "    sigma_col = dict()\n",
    "\n",
    "    for column in column_to_impute:\n",
    "        mu_col[column] = dataset[column].mean()\n",
    "        sigma_col[column] = dataset[column].std()\n",
    "\n",
    "    print(mu_col)\n",
    "    print(sigma_col)\n",
    "\n",
    "    return data, ground_truth, mu_col, sigma_col"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Without normalisation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year', 'month', 'day', 'latitude', 'longitude', 'altitude', 'wind_direction', 'wind_speed', 'temperature', 'humidity', 'dew_point', 'precipitations']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'column_to_impute' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_4037/3805479006.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mground_truth\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmu_col\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msigma_col\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnormalization\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mmcmc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mMCMC\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mNUTS\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_ground_truth\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_warmup\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1000\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_samples\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1000\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mmcmc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrandom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPRNGKey\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mground_truth\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mground_truth\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnan_columns\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmu\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmu_col\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msigma\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msigma_col\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m# Print the statistics of posterior samples collected during running this MCMC instance. (documentation)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_4037/1632595543.py\u001B[0m in \u001B[0;36mget_data\u001B[0;34m(normalization)\u001B[0m\n\u001B[1;32m     27\u001B[0m     \u001B[0msigma_col\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 29\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mcolumn\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mcolumn_to_impute\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     30\u001B[0m         \u001B[0mmu_col\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcolumn\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcolumn\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m         \u001B[0msigma_col\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcolumn\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcolumn\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'column_to_impute' is not defined"
     ]
    }
   ],
   "source": [
    "data, ground_truth, mu_col, sigma_col = get_data(normalization=False)\n",
    "\n",
    "mcmc = MCMC(NUTS(model_ground_truth), num_warmup=1000, num_samples=1000)\n",
    "mcmc.run(random.PRNGKey(0), **data, ground_truth=ground_truth, nan_columns = [], mu=mu_col, sigma=sigma_col)\n",
    "# Print the statistics of posterior samples collected during running this MCMC instance. (documentation)\n",
    "mcmc.print_summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With normalisation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data, ground_truth, mu_col, sigma_col = get_data(normalization=True)\n",
    "\n",
    "mcmc = MCMC(NUTS(model_ground_truth), num_warmup=1000, num_samples=1000)\n",
    "mcmc.run(random.PRNGKey(0), **data, ground_truth=ground_truth, nan_columns = [], mu=mu_col, sigma=sigma_col)\n",
    "# Print the statistics of posterior samples collected during running this MCMC instance. (documentation)\n",
    "mcmc.print_summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpyro.infer import Predictive\n",
    "\n",
    "posterior = mcmc.get_samples()\n",
    "ground_truth_pred = Predictive(model_ground_truth, posterior)(random.PRNGKey(1), **data,  nan_columns = [])[\"ground_truth\"]\n",
    "ground_truth_pred = ground_truth_pred.mean(axis=0)\n",
    "\n",
    "print(len(ground_truth_pred))\n",
    "print(ground_truth_pred)\n",
    "print(ground_truth)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def m_mape(y_true, y_predict):\n",
    "    n = len(y_true)\n",
    "    At = np.array(y_true) + 1\n",
    "    Ft = np.array(y_predict) + 1\n",
    "\n",
    "    res = ((100/n)*(np.sum(np.abs((Ft-At)/At))))\n",
    "    return res\n",
    "\n",
    "print(\"MAPE : \", m_mape(ground_truth, ground_truth_pred))\n",
    "print(\"Mean Absolute Error : \", mean_absolute_error(ground_truth, ground_truth_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imputation part\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../data/X_station_day.csv\")\n",
    "del dataset['station_id']\n",
    "ground_truth = dataset.ground_truth.values\n",
    "del dataset['ground_truth']\n",
    "\n",
    "columns = dataset.columns.tolist()\n",
    "print(columns)\n",
    "\n",
    "normalisation_infos = get_normalization_infos(dataset, columns=columns)\n",
    "dataset = normalize(dataset, normalisation_infos)\n",
    "\n",
    "# column_to_impute = ['wind_direction', 'temperature', 'humidity', 'dew_point', 'precipitations']\n",
    "column_to_impute = ['wind_direction'] # , 'wind_speed']\n",
    "dataset = create_nans(dataset, column_to_impute, 0.01)\n",
    "\n",
    "print(dataset['precipitations'].isna().sum())\n",
    "\n",
    "data = dict(\n",
    "    latitude = dataset.latitude.values,\n",
    "    longitude = dataset.longitude.values,\n",
    "    altitude = dataset.altitude.values,\n",
    "    wind_direction = dataset.wind_direction.values,\n",
    "    wind_speed = dataset.wind_speed.values,\n",
    "    temperature = dataset.temperature.values,\n",
    "    humidity = dataset.humidity.values,\n",
    "    dew_point = dataset.dew_point.values,\n",
    "    precipitations = dataset.precipitations.values,\n",
    ")\n",
    "\n",
    "mu_col = dict()\n",
    "sigma_col = dict()\n",
    "\n",
    "for column in column_to_impute:\n",
    "    mu_col[column] = dataset[column].mean()\n",
    "    sigma_col[column] = dataset[column].std()\n",
    "\n",
    "print(mu_col)\n",
    "print(sigma_col)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# WITH NaNS (ratio 0.4)\n",
    "mcmc = MCMC(NUTS(model_ground_truth), num_warmup=1000, num_samples=1000)\n",
    "mcmc.run(random.PRNGKey(0), **data, ground_truth=ground_truth, nan_columns = column_to_impute, mu=mu_col, sigma=sigma_col)\n",
    "# Print the statistics of posterior samples collected during running this MCMC instance. (documentation)\n",
    "mcmc.print_summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpyro.infer import Predictive\n",
    "\n",
    "posterior = mcmc.get_samples()\n",
    "ground_truth_pred = Predictive(model_ground_truth, posterior)(random.PRNGKey(1), **data,  nan_columns = [])[\"ground_truth\"]\n",
    "ground_truth_pred = ground_truth_pred.mean(axis=0)\n",
    "# print(\"Accuracy:\", (survived_pred == survived).sum() / survived.shape[0])\n",
    "\n",
    "print(len(ground_truth_pred))\n",
    "print(ground_truth_pred)\n",
    "print(ground_truth)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def m_mape(y_true, y_predict):\n",
    "    n = len(y_true)\n",
    "    At = np.array(y_true) + 1\n",
    "    Ft = np.array(y_predict) + 1\n",
    "\n",
    "    res = ((100/n)*(np.sum(np.abs((Ft-At)/At))))\n",
    "    return res\n",
    "\n",
    "print(\"MAPE : \", m_mape(ground_truth, ground_truth_pred))\n",
    "print(\"Mean Absolute Error : \", mean_absolute_error(ground_truth, ground_truth_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imputation by inference"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def model_inference_wind_direction(\n",
    "        latitude, longitude, altitude, wind_speed, temperature, humidity, dew_point, precipitations, mu=None, sigma=None, wind_direction=None,\n",
    "        nan_columns = None, prec_nan=False\n",
    "):\n",
    "    lat, long, alt, w_s, temp, hum, d_pt, prec = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    default = numpyro.sample(\"default\", dist.Normal(0.0, 0.2))\n",
    "    if latitude is not None:\n",
    "        bayes_latitude = numpyro.sample('bayes_latitude', dist.Normal(0, 1))\n",
    "        lat = bayes_latitude * latitude\n",
    "    if longitude is not None:\n",
    "        bayes_longitude = numpyro.sample('bayes_longitude', dist.Normal(0, 1))\n",
    "        long = bayes_longitude * longitude\n",
    "    if altitude is not None:\n",
    "        bayes_altitude = numpyro.sample('bayes_altitude', dist.Normal(0, 1))\n",
    "        alt = bayes_altitude * altitude\n",
    "    if wind_speed is not None:\n",
    "            bayes_wind_speed = numpyro.sample('bayes_wind_speed', dist.Normal(0, 1))\n",
    "            w_s = bayes_wind_speed * wind_speed\n",
    "    if temperature is not None:\n",
    "            bayes_temperature = numpyro.sample('bayes_temperature', dist.Normal(0, 1))\n",
    "            temp = bayes_temperature * temperature\n",
    "    if humidity is not None:\n",
    "            bayes_humidity = numpyro.sample('bayes_humidity', dist.Normal(0, 1))\n",
    "            hum = bayes_humidity * humidity\n",
    "    if dew_point is not None:\n",
    "            bayes_dew_point = numpyro.sample('bayes_dew_point', dist.Normal(0, 1))\n",
    "            d_pt = bayes_dew_point * dew_point\n",
    "    if precipitations is not None:\n",
    "            bayes_precipitations = numpyro.sample('bayes_precipitations', dist.Normal(0, 1))\n",
    "            prec = bayes_precipitations * precipitations\n",
    "\n",
    "    sigma_model = numpyro.sample(\"sigma\", dist.Exponential(1.0))\n",
    "    if not prec_nan:\n",
    "        mu_model = default + lat + long + alt + w_s + temp + hum + d_pt + prec\n",
    "    else:\n",
    "        mu_model = default + lat + long + alt + w_s + temp + hum + d_pt\n",
    "    # print(\"sigma\", sigma_model, \"mu\", mu_model)\n",
    "    numpyro.sample(\"wind_direction\", dist.Normal(mu_model, sigma_model), obs=wind_direction)\n",
    "\n",
    "def model_inference_precipitation(\n",
    "        latitude, longitude, altitude, wind_direction, wind_speed, temperature, humidity, dew_point, mu=None, sigma=None, precipitations=None,\n",
    "        nan_columns = None\n",
    "):\n",
    "    lat, long, alt, w_d, w_s, temp, hum, d_pt = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    default = numpyro.sample(\"default\", dist.Normal(0.0, 0.2))\n",
    "    if latitude is not None:\n",
    "        bayes_latitude = numpyro.sample('bayes_latitude', dist.Normal(0, 1))\n",
    "        lat = bayes_latitude * latitude\n",
    "    if longitude is not None:\n",
    "        bayes_longitude = numpyro.sample('bayes_longitude', dist.Normal(0, 1))\n",
    "        long = bayes_longitude * longitude\n",
    "    if altitude is not None:\n",
    "        bayes_altitude = numpyro.sample('bayes_altitude', dist.Normal(0, 1))\n",
    "        alt = bayes_altitude * altitude\n",
    "    if wind_direction is not None:\n",
    "        bayes_wind_direction = numpyro.sample('bayes_wind_direction', dist.Normal(0, 1))\n",
    "        w_d = bayes_wind_direction* wind_direction\n",
    "    if wind_speed is not None:\n",
    "        bayes_wind_speed = numpyro.sample('bayes_wind_speed', dist.Normal(0, 1))\n",
    "        w_s = bayes_wind_speed * wind_speed\n",
    "    if temperature is not None:\n",
    "        bayes_temperature = numpyro.sample('bayes_temperature', dist.Normal(0, 1))\n",
    "        temp = bayes_temperature * temperature\n",
    "    if humidity is not None:\n",
    "        bayes_humidity = numpyro.sample('bayes_humidity', dist.Normal(0, 1))\n",
    "        hum = bayes_humidity * humidity\n",
    "    if dew_point is not None:\n",
    "        bayes_dew_point = numpyro.sample('bayes_dew_point', dist.Normal(0, 1))\n",
    "        d_pt = bayes_dew_point * dew_point\n",
    "\n",
    "    sigma_model = numpyro.sample(\"sigma\", dist.Exponential(1.0))\n",
    "    mu_model = default + lat + long + alt + w_d + w_s + temp + hum + d_pt\n",
    "    # print(\"sigma\", sigma_model, \"mu\", mu_model)\n",
    "    numpyro.sample(\"precipitations\", dist.Normal(mu_model, sigma_model), obs=precipitations)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Get data and simulate some NaNs\n",
    "#### Separate the data with NaNs from the others and create the data to use to fit the wind_direction inference model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_data_imputation_wd(ratio = 0.01):\n",
    "    dataset = pd.read_csv(\"../data/X_station_day.csv\")\n",
    "    del dataset['station_id']\n",
    "\n",
    "    columns = ['latitude', 'longitude', 'altitude', 'wind_direction', 'wind_speed', 'temperature', 'humidity', 'dew_point', 'precipitations']\n",
    "    print(columns)\n",
    "\n",
    "    normalisation_infos = get_normalization_infos(dataset, columns=columns)\n",
    "    dataset.loc[:, columns] = normalize(dataset.loc[:, columns], normalisation_infos)\n",
    "\n",
    "    nanidx = rd.sample(range(0, dataset.shape[0]), int(ratio*dataset.shape[0]))\n",
    "\n",
    "    true_wind_direction = dataset.iloc[nanidx]['wind_direction']\n",
    "\n",
    "    dataset.loc[nanidx, 'wind_direction'] = np.nan * np.ones(shape=(int(ratio*dataset.shape[0]),1))\n",
    "\n",
    "    print(dataset['wind_direction'].isna().sum())\n",
    "\n",
    "    return dataset, nanidx, true_wind_direction\n",
    "\n",
    "def prepare_data_imputation_wd(dataset, nanidx):\n",
    "    # nanidx = np.array(np.isnan(dataset['wind_direction']).astype(int)).nonzero()[0]\n",
    "    dataset_to_impute = dataset.iloc[nanidx]\n",
    "\n",
    "    dataset = dataset.drop(index=nanidx)\n",
    "\n",
    "    print(dataset['wind_direction'].isna().sum())\n",
    "\n",
    "    wind_direction = dataset.wind_direction.values\n",
    "\n",
    "    data = dict(\n",
    "        latitude = dataset.latitude.values,\n",
    "        longitude = dataset.longitude.values,\n",
    "        altitude = dataset.altitude.values,\n",
    "        wind_speed = dataset.wind_speed.values,\n",
    "        temperature = dataset.temperature.values,\n",
    "        humidity = dataset.humidity.values,\n",
    "        dew_point = dataset.dew_point.values,\n",
    "        precipitations = dataset.precipitations.values,\n",
    "    )\n",
    "\n",
    "    data_to_impute = dict(\n",
    "        latitude = dataset_to_impute.latitude.values,\n",
    "        longitude = dataset_to_impute.longitude.values,\n",
    "        altitude = dataset_to_impute.altitude.values,\n",
    "        wind_speed = dataset_to_impute.wind_speed.values,\n",
    "        temperature = dataset_to_impute.temperature.values,\n",
    "        humidity = dataset_to_impute.humidity.values,\n",
    "        dew_point = dataset_to_impute.dew_point.values,\n",
    "        precipitations = dataset_to_impute.precipitations.values,\n",
    "    )\n",
    "\n",
    "    return dataset, dataset_to_impute, data, data_to_impute, wind_direction\n",
    "\n",
    "def get_data_imputation_prec(ratio = 0.01, dataset=None):\n",
    "    if dataset is None:\n",
    "        dataset = pd.read_csv(\"../data/X_station_day.csv\")\n",
    "        del dataset['station_id']\n",
    "\n",
    "        columns = ['latitude', 'longitude', 'altitude', 'wind_direction', 'wind_speed', 'temperature', 'humidity', 'dew_point', 'precipitations']\n",
    "        print(columns)\n",
    "\n",
    "        normalisation_infos = get_normalization_infos(dataset, columns=columns)\n",
    "        dataset.loc[:, columns] = normalize(dataset.loc[:, columns], normalisation_infos)\n",
    "\n",
    "    nanidx = rd.sample(range(0, dataset.shape[0]), int(ratio*dataset.shape[0]))\n",
    "\n",
    "    true_precipitations= dataset.iloc[nanidx]['precipitations']\n",
    "\n",
    "    dataset.loc[nanidx, 'precipitations'] = np.nan * np.ones(shape=(int(ratio*dataset.shape[0]),1))\n",
    "\n",
    "    print(dataset['precipitations'].isna().sum())\n",
    "\n",
    "    return dataset, nanidx, true_precipitations\n",
    "\n",
    "def prepare_data_imputation_prec(dataset, nanidx):\n",
    "    # nanidx = np.array(np.isnan(dataset['wind_direction']).astype(int)).nonzero()[0]\n",
    "    dataset_to_impute = dataset.iloc[nanidx]\n",
    "\n",
    "    dataset = dataset.drop(index=nanidx)\n",
    "\n",
    "    print(dataset['precipitations'].isna().sum())\n",
    "\n",
    "\n",
    "    precipitations = dataset.precipitations.values\n",
    "\n",
    "    data = dict(\n",
    "        latitude = dataset.latitude.values,\n",
    "        longitude = dataset.longitude.values,\n",
    "        altitude = dataset.altitude.values,\n",
    "        wind_direction = dataset.wind_direction.values,\n",
    "        wind_speed = dataset.wind_speed.values,\n",
    "        temperature = dataset.temperature.values,\n",
    "        humidity = dataset.humidity.values,\n",
    "        dew_point = dataset.dew_point.values,\n",
    "    )\n",
    "\n",
    "    data_to_impute = dict(\n",
    "        latitude = dataset_to_impute.latitude.values,\n",
    "        longitude = dataset_to_impute.longitude.values,\n",
    "        altitude = dataset_to_impute.altitude.values,\n",
    "        wind_direction = dataset_to_impute.wind_direction.values,\n",
    "        wind_speed = dataset_to_impute.wind_speed.values,\n",
    "        temperature = dataset_to_impute.temperature.values,\n",
    "        humidity = dataset_to_impute.humidity.values,\n",
    "        dew_point = dataset_to_impute.dew_point.values,\n",
    "    )\n",
    "\n",
    "    return dataset, dataset_to_impute, data, data_to_impute, precipitations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fit the inference model and predict the NaNs values using MCMC (wind_direction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ratios = [0.01, 0.1, 0.25, 0.5, 0.75, 0.85]\n",
    "\n",
    "time_imputation = []\n",
    "mape_imputation = []\n",
    "mae_imputation = []\n",
    "time_prediction = []\n",
    "mape_prediction = []\n",
    "mae_prediction = []\n",
    "\n",
    "for ratio in ratios:\n",
    "    print('ratio', ratio)\n",
    "    dataset, nanidx, true_wind_direction = get_data_imputation_wd(ratio)\n",
    "    dataset, dataset_to_impute, data, data_to_impute, wind_direction = prepare_data_imputation_wd(dataset, nanidx)\n",
    "\n",
    "    # IMPUTATION\n",
    "\n",
    "    start_time = time.time()\n",
    "    mcmc_imputation = MCMC(NUTS(model_inference_wind_direction), num_warmup=1000, num_samples=1000)\n",
    "    mcmc_imputation.run(random.PRNGKey(0), **data, wind_direction=wind_direction, nan_columns = [], mu=dict(), sigma=dict())\n",
    "    # Print the statistics of posterior samples collected during running this MCMC instance. (documentation)\n",
    "    mcmc_imputation.print_summary()\n",
    "\n",
    "    posterior_imputation = mcmc_imputation.get_samples()\n",
    "    imputed_wind_direction = Predictive(model_inference_wind_direction, posterior_imputation)(random.PRNGKey(1), **data_to_impute,  nan_columns = [])[\"wind_direction\"]\n",
    "    imputed_wind_direction = imputed_wind_direction.mean(axis=0)\n",
    "    time_imputation.append(time.time() - start_time)\n",
    "\n",
    "    print(\"MAPE : \", m_mape(true_wind_direction, imputed_wind_direction))\n",
    "    mape_imputation.append(m_mape(true_wind_direction, imputed_wind_direction))\n",
    "    print(\"Mean Absolute Error : \", mean_absolute_error(true_wind_direction, imputed_wind_direction))\n",
    "    mae_imputation.append(mean_absolute_error(true_wind_direction, imputed_wind_direction))\n",
    "\n",
    "\n",
    "    # PREPARE DATA FOR PREDICTION\n",
    "\n",
    "    dataset_to_impute['wind_direction'] = imputed_wind_direction\n",
    "    dataset = pd.concat([dataset, dataset_to_impute], axis=0)\n",
    "    ground_truth = dataset.ground_truth.values\n",
    "    del dataset['ground_truth']\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dataset, ground_truth, test_size=0.33)\n",
    "\n",
    "    # print(dataset['wind_direction'].isna().sum())\n",
    "\n",
    "    data_train = dict(\n",
    "        latitude = x_train.latitude.values,\n",
    "        longitude = x_train.longitude.values,\n",
    "        altitude = x_train.altitude.values,\n",
    "        wind_direction = x_train.wind_direction.values,\n",
    "        wind_speed = x_train.wind_speed.values,\n",
    "        temperature = x_train.temperature.values,\n",
    "        humidity = x_train.humidity.values,\n",
    "        dew_point = x_train.dew_point.values,\n",
    "        precipitations = x_train.precipitations.values,\n",
    "    )\n",
    "\n",
    "    data_test = dict(\n",
    "        latitude = x_test.latitude.values,\n",
    "        longitude = x_test.longitude.values,\n",
    "        altitude = x_test.altitude.values,\n",
    "        wind_direction = x_test.wind_direction.values,\n",
    "        wind_speed = x_test.wind_speed.values,\n",
    "        temperature = x_test.temperature.values,\n",
    "        humidity = x_test.humidity.values,\n",
    "        dew_point = x_test.dew_point.values,\n",
    "        precipitations = x_test.precipitations.values,\n",
    "    )\n",
    "\n",
    "    mcmc_prediction = MCMC(NUTS(model_ground_truth), num_warmup=1000, num_samples=1000)\n",
    "    mcmc_prediction.run(random.PRNGKey(0), **data_train, ground_truth=y_train, nan_columns = [], mu=dict(), sigma=dict())\n",
    "    # Print the statistics of posterior samples collected during running this MCMC instance. (documentation)\n",
    "    mcmc_prediction.print_summary()\n",
    "\n",
    "    posterior_prediction = mcmc_prediction.get_samples()\n",
    "    ground_truth_pred = Predictive(model_ground_truth, posterior_prediction)(random.PRNGKey(1), **data_test,  nan_columns = [])[\"ground_truth\"]\n",
    "    ground_truth_pred = ground_truth_pred.mean(axis=0)\n",
    "\n",
    "    print(\"MAPE : \", m_mape(y_test, ground_truth_pred))\n",
    "    mape_prediction.append(m_mape(y_test, ground_truth_pred))\n",
    "    print(\"Mean Absolute Error : \", mean_absolute_error(y_test, ground_truth_pred))\n",
    "    mae_prediction.append(mean_absolute_error(y_test, ground_truth_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"time_imputation =\", time_imputation)\n",
    "print('mape_imputation = ', mape_imputation)\n",
    "print('mae_imputation = ', mae_imputation)\n",
    "print('time_prediction = ', time_prediction )\n",
    "print('mape_prediction = ', mape_prediction)\n",
    "print('mae_prediction = ', mae_prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results for imputation on wind_direction (just train)\n",
    "\n",
    "ratios = [0.01, 0.1, 0.2, 0.3, 0.5, 0.7]\n",
    "\n",
    "time_imputation = [498.4595172405243, 535.9812779426575, 382.225394487381, 467.5977392196655, 207.57443261146545, 131.66128158569336]\n",
    "mape_imputation =  [10.661021432629596, 10.66094987616098, 10.534959470297153, 10.601560210130817, 10.578586794722735, 10.578794819419919]\n",
    "mae_imputation =  [0.15565755190667555, 0.15548198558043402, 0.15398647534098273, 0.15473225996057607, 0.15471727357235873, 0.15473207181873366]\n",
    "time_prediction =  []\n",
    "mape_prediction =  [115.09920384958139, 115.10145605712758, 115.22304792014107, 115.20514023106551, 115.29881327654412, 115.46439420994176]\n",
    "mae_prediction =  [2.411045576079181, 2.411469252298278, 2.4130132029841653, 2.4120047693693074, 2.4130731608806273, 2.4157148375452886]\n",
    "\n",
    "### Results for imputation on wind_direction (train and test)\n",
    "\n",
    "ratios = [0.01, 0.1, 0.25, 0.5, 0.75, 0.85]\n",
    "time_imputation = [760.7768249511719, 833.6295111179352, 331.03947353363037, 210.5356183052063, 100.60632395744324, 69.34340333938599]\n",
    "mape_imputation =  [10.655264626915809, 10.499994185083757, 10.681917154662534, 10.638655587883045, 10.596149833552735, 10.596493616639869]\n",
    "mae_imputation =  [0.15591639626159046, 0.153218699400214, 0.15589513935226562, 0.15519977132031357, 0.1550552133342025, 0.1549220600102269]\n",
    "time_prediction =  []\n",
    "mape_prediction =  [115.4349735877578, 116.48780259488963, 114.29392445601097, 115.2284456187796, 116.77062778921001, 115.70286894467233]\n",
    "mae_prediction =  [2.4142372593398025, 2.4023796948936806, 2.4387429669468874, 2.409663312415465, 2.4045725457652907, 2.4021950186983516]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fit the inference model and predict the NaNs values using MCMC (precipitation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ratios = [0.01, 0.1, 0.25, 0.5, 0.75, 0.85]\n",
    "\n",
    "time_imputation = []\n",
    "mape_imputation = []\n",
    "mae_imputation = []\n",
    "time_prediction = []\n",
    "mape_prediction = []\n",
    "mae_prediction = []\n",
    "\n",
    "for ratio in ratios:\n",
    "    print('ratio', ratio)\n",
    "    dataset, nanidx, true_precipitations = get_data_imputation_prec(ratio)\n",
    "    dataset, dataset_to_impute, data, data_to_impute, precipitations = prepare_data_imputation_prec(dataset, nanidx)\n",
    "\n",
    "    # IMPUTATION\n",
    "\n",
    "    start_time = time.time()\n",
    "    mcmc_imputation = MCMC(NUTS(model_inference_precipitation), num_warmup=1000, num_samples=1000)\n",
    "    mcmc_imputation.run(random.PRNGKey(0), **data, precipitations=precipitations, nan_columns = [], mu=dict(), sigma=dict())\n",
    "    # Print the statistics of posterior samples collected during running this MCMC instance. (documentation)\n",
    "    mcmc_imputation.print_summary()\n",
    "\n",
    "    posterior_imputation = mcmc_imputation.get_samples()\n",
    "    imputed_precipitation = Predictive(model_inference_precipitation, posterior_imputation)(random.PRNGKey(1), **data_to_impute,  nan_columns = [])[\"precipitations\"]\n",
    "    imputed_precipitation = imputed_precipitation.mean(axis=0)\n",
    "    time_imputation.append(time.time() - start_time)\n",
    "\n",
    "    print(\"MAPE : \", m_mape(true_precipitations, imputed_precipitation))\n",
    "    mape_imputation.append(m_mape(true_precipitations, imputed_precipitation))\n",
    "    print(\"Mean Absolute Error : \", mean_absolute_error(true_precipitations, imputed_precipitation))\n",
    "    mae_imputation.append(mean_absolute_error(true_precipitations, imputed_precipitation))\n",
    "\n",
    "\n",
    "    # PREPARE DATA FOR PREDICTION\n",
    "\n",
    "    dataset_to_impute['precipitations'] = imputed_precipitation\n",
    "    dataset = pd.concat([dataset, dataset_to_impute], axis=0)\n",
    "    ground_truth = dataset.ground_truth.values\n",
    "    del dataset['ground_truth']\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dataset, ground_truth, test_size=0.33)\n",
    "\n",
    "    # print(dataset['wind_direction'].isna().sum())\n",
    "\n",
    "    data_train = dict(\n",
    "        latitude = x_train.latitude.values,\n",
    "        longitude = x_train.longitude.values,\n",
    "        altitude = x_train.altitude.values,\n",
    "        wind_direction = x_train.wind_direction.values,\n",
    "        wind_speed = x_train.wind_speed.values,\n",
    "        temperature = x_train.temperature.values,\n",
    "        humidity = x_train.humidity.values,\n",
    "        dew_point = x_train.dew_point.values,\n",
    "        precipitations = x_train.precipitations.values,\n",
    "    )\n",
    "\n",
    "    data_test = dict(\n",
    "        latitude = x_test.latitude.values,\n",
    "        longitude = x_test.longitude.values,\n",
    "        altitude = x_test.altitude.values,\n",
    "        wind_direction = x_test.wind_direction.values,\n",
    "        wind_speed = x_test.wind_speed.values,\n",
    "        temperature = x_test.temperature.values,\n",
    "        humidity = x_test.humidity.values,\n",
    "        dew_point = x_test.dew_point.values,\n",
    "        precipitations = x_test.precipitations.values,\n",
    "    )\n",
    "\n",
    "    mcmc_prediction = MCMC(NUTS(model_ground_truth), num_warmup=1000, num_samples=1000)\n",
    "    mcmc_prediction.run(random.PRNGKey(0), **data_train, ground_truth=y_train, nan_columns = [], mu=dict(), sigma=dict())\n",
    "    # Print the statistics of posterior samples collected during running this MCMC instance. (documentation)\n",
    "    mcmc_prediction.print_summary()\n",
    "\n",
    "    posterior_prediction = mcmc_prediction.get_samples()\n",
    "    ground_truth_pred = Predictive(model_ground_truth, posterior_prediction)(random.PRNGKey(1), **data_test,  nan_columns = [])[\"ground_truth\"]\n",
    "    ground_truth_pred = ground_truth_pred.mean(axis=0)\n",
    "\n",
    "    print(\"MAPE : \", m_mape(y_test, ground_truth_pred))\n",
    "    mape_prediction.append(m_mape(y_test, ground_truth_pred))\n",
    "    print(\"Mean Absolute Error : \", mean_absolute_error(y_test, ground_truth_pred))\n",
    "    mae_prediction.append(mean_absolute_error(y_test, ground_truth_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"time_imputation =\", time_imputation)\n",
    "print('mape_imputation = ', mape_imputation)\n",
    "print('mae_imputation = ', mae_imputation)\n",
    "print('time_prediction = ', time_prediction )\n",
    "print('mape_prediction = ', mape_prediction)\n",
    "print('mae_prediction = ', mae_prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results for imputation on precipitations (just train)\n",
    "\n",
    "\n",
    "ratios = [0.01, 0.1, 0.25, 0.5, 0.75, 0.85]\n",
    "\n",
    "time_imputation = [334.5759816169739, 220.93195962905884, 223.3536810874939, 218.35092449188232, 75.44321203231812, 58.480687856674194]\n",
    "mape_imputation =  [2.69251744495105, 2.6656074188353105, 2.7072722875026463, 2.6965653750125296, 2.7166022716786093, 2.7161747234117986]\n",
    "mae_imputation =  [0.02927843191081118, 0.02888885154555619, 0.029249887627131644, 0.02910631590598334, 0.02934373638911998, 0.02933613892276303]\n",
    "time_prediction =  []\n",
    "mape_prediction =  [115.14346397586787, 115.5460603302976, 116.49281661244719, 117.93400404409374, 119.23363228520006, 119.83836222691068]\n",
    "mae_prediction =  [2.4117583647778793, 2.4172633556710967, 2.430496724987021, 2.4493258274049, 2.466964335067219, 2.4742455842166406]\n",
    "\n",
    "### Results for imputation on precipitations (train and test)\n",
    "\n",
    "time_imputation = [345.27573561668396, 278.56666231155396, 304.60888600349426, 165.8144268989563, 97.52951622009277, 48.52631092071533]\n",
    "mape_imputation =  [2.579436331117188, 2.7146133812855884, 2.701725408799627, 2.6964253859506884, 2.7054057318343734, 2.70623604950047]\n",
    "mae_imputation =  [0.027640181257082227, 0.029349886855223765, 0.029184162608646508, 0.029177849803427757, 0.029270931863838903, 0.029232264090179393]\n",
    "time_prediction =  []\n",
    "mape_prediction =  [114.88637682769046, 116.65396876746904, 118.48552655302022, 118.95122414676707, 119.73960195911792, 119.28144026832175]\n",
    "mae_prediction =  [2.409019031646397, 2.4180447872986544, 2.422017444721502, 2.4446329493926515, 2.464761624828655, 2.4760137519946217]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imputation on precipitations AND wind_direction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_data_imputation_wd_prec(ratio = 0.01):\n",
    "    dataset = pd.read_csv(\"../data/X_station_day.csv\")\n",
    "    del dataset['station_id']\n",
    "\n",
    "    columns = ['latitude', 'longitude', 'altitude', 'wind_direction', 'wind_speed', 'temperature', 'humidity', 'dew_point', 'precipitations']\n",
    "    print(columns)\n",
    "\n",
    "    normalisation_infos = get_normalization_infos(dataset, columns=columns)\n",
    "    dataset.loc[:, columns] = normalize(dataset.loc[:, columns], normalisation_infos)\n",
    "\n",
    "    nanidx_wd = rd.sample(range(0, dataset.shape[0]), int(ratio*dataset.shape[0]))\n",
    "    nanidx_prec = rd.sample(range(0, dataset.shape[0]), int(ratio*dataset.shape[0]))\n",
    "\n",
    "    # print(nanidx_wd)\n",
    "    # print(nanidx_prec)\n",
    "\n",
    "    true_wind_direction = dataset.iloc[nanidx_wd]['wind_direction']\n",
    "    true_precipitations = dataset.iloc[nanidx_prec]['precipitations']\n",
    "\n",
    "    dataset.loc[nanidx_wd, 'wind_direction'] = np.nan * np.ones(shape=(int(ratio*dataset.shape[0]),1))\n",
    "    dataset.loc[nanidx_prec, 'precipitations'] = np.nan * np.ones(shape=(int(ratio*dataset.shape[0]),1))\n",
    "\n",
    "    # print(dataset['wind_direction'].isna().sum())\n",
    "    # print(dataset['precipitations'].isna().sum())\n",
    "\n",
    "    return dataset, nanidx_wd, nanidx_prec, true_wind_direction, true_precipitations\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio 0.75\n",
      "['latitude', 'longitude', 'altitude', 'wind_direction', 'wind_speed', 'temperature', 'humidity', 'dew_point', 'precipitations']\n",
      "61590\n",
      "61590\n",
      "61590\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:54<00:00, 11.47it/s, 511 steps of size 1.01e-02. acc. prob=0.93] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                            mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "        bayes_altitude      0.04      0.01      0.04      0.03      0.05    915.17      1.00\n",
      "       bayes_dew_point      4.42      0.17      4.42      4.15      4.68    225.93      1.00\n",
      "        bayes_humidity     -1.23      0.06     -1.23     -1.32     -1.13    234.89      1.00\n",
      "        bayes_latitude      0.01      0.01      0.01     -0.00      0.02    832.19      1.00\n",
      "       bayes_longitude      0.01      0.01      0.01      0.00      0.02    718.80      1.01\n",
      "  bayes_precipitations     -0.05      0.99     -0.06     -1.76      1.44    651.88      1.00\n",
      "     bayes_temperature     -3.44      0.14     -3.45     -3.66     -3.21    226.85      1.00\n",
      "      bayes_wind_speed      0.47      0.02      0.47      0.45      0.50    704.33      1.00\n",
      "               default      0.53      0.02      0.53      0.49      0.57    293.30      1.00\n",
      "                 sigma      0.19      0.00      0.19      0.19      0.19    746.62      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:00<00:00, 16.58it/s, 255 steps of size 8.72e-03. acc. prob=0.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                            mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "        bayes_altitude      0.01      0.00      0.01      0.00      0.01   1398.46      1.00\n",
      "       bayes_dew_point     -0.49      0.04     -0.49     -0.57     -0.43    125.41      1.00\n",
      "        bayes_humidity      0.30      0.02      0.30      0.27      0.32    127.44      1.00\n",
      "        bayes_latitude     -0.01      0.00     -0.01     -0.01     -0.01   1287.27      1.00\n",
      "       bayes_longitude      0.01      0.00      0.01      0.01      0.01   1180.47      1.00\n",
      "     bayes_temperature      0.44      0.04      0.44      0.39      0.50    125.11      1.00\n",
      "  bayes_wind_direction      0.02      0.00      0.02      0.01      0.02    575.96      1.00\n",
      "      bayes_wind_speed      0.19      0.00      0.19      0.18      0.19    561.28      1.00\n",
      "               default     -0.17      0.01     -0.17     -0.18     -0.16    146.48      1.00\n",
      "                 sigma      0.05      0.00      0.05      0.05      0.05    440.96      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [03:27<00:00,  9.62it/s, 63 steps of size 3.44e-02. acc. prob=0.94] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                            mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "        bayes_altitude      0.52      0.08      0.52      0.39      0.65   1060.42      1.00\n",
      "       bayes_dew_point      0.61      0.64      0.60     -0.43      1.65    407.20      1.00\n",
      "        bayes_humidity      0.75      0.23      0.73      0.34      1.09    398.50      1.00\n",
      "        bayes_latitude      0.11      0.08      0.11     -0.02      0.24   1182.87      1.00\n",
      "       bayes_longitude     -0.22      0.07     -0.22     -0.33     -0.09    837.53      1.00\n",
      "  bayes_precipitations     10.40      0.56     10.42      9.52     11.31    916.65      1.00\n",
      "     bayes_temperature     -1.08      0.53     -1.07     -1.88     -0.18    406.27      1.00\n",
      "  bayes_wind_direction      0.98      0.18      0.98      0.68      1.26    760.09      1.00\n",
      "      bayes_wind_speed      5.15      0.23      5.16      4.76      5.52    611.98      1.00\n",
      "               default     -0.12      0.14     -0.12     -0.35      0.10    581.75      1.00\n",
      "                 sigma      4.15      0.01      4.15      4.13      4.17   1190.03      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "MAPE :  121.0717496822495\n",
      "Mean Absolute Error :  2.4638451731754847\n",
      "ratio 0.85\n",
      "['latitude', 'longitude', 'altitude', 'wind_direction', 'wind_speed', 'temperature', 'humidity', 'dew_point', 'precipitations']\n",
      "69802\n",
      "69802\n",
      "69802\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:39<00:00, 20.18it/s, 511 steps of size 7.81e-03. acc. prob=0.96] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                            mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "        bayes_altitude      0.04      0.01      0.04      0.03      0.05   1059.76      1.00\n",
      "       bayes_dew_point      3.92      0.22      3.92      3.51      4.23    329.16      1.01\n",
      "        bayes_humidity     -1.03      0.08     -1.04     -1.16     -0.89    327.82      1.01\n",
      "        bayes_latitude      0.02      0.01      0.02      0.00      0.03   1258.09      1.00\n",
      "       bayes_longitude      0.03      0.01      0.03      0.01      0.04    930.76      1.00\n",
      "  bayes_precipitations     -0.02      0.98     -0.03     -1.61      1.55   1040.26      1.00\n",
      "     bayes_temperature     -3.02      0.19     -3.02     -3.28     -2.66    327.99      1.01\n",
      "      bayes_wind_speed      0.44      0.02      0.44      0.40      0.47   1039.59      1.00\n",
      "               default      0.46      0.03      0.46      0.40      0.50    371.50      1.01\n",
      "                 sigma      0.19      0.00      0.19      0.19      0.19    907.88      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:29<00:00, 22.26it/s, 255 steps of size 8.09e-03. acc. prob=0.94] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                            mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "        bayes_altitude      0.01      0.00      0.01      0.00      0.01    926.95      1.00\n",
      "       bayes_dew_point     -0.45      0.06     -0.45     -0.53     -0.35    307.64      1.00\n",
      "        bayes_humidity      0.27      0.02      0.27      0.23      0.30    302.68      1.00\n",
      "        bayes_latitude     -0.01      0.00     -0.01     -0.01     -0.01   1032.38      1.00\n",
      "       bayes_longitude      0.01      0.00      0.01      0.00      0.01   1068.69      1.00\n",
      "     bayes_temperature      0.40      0.05      0.40      0.31      0.47    306.81      1.00\n",
      "  bayes_wind_direction      0.02      0.01      0.02      0.01      0.03    568.12      1.00\n",
      "      bayes_wind_speed      0.18      0.01      0.18      0.17      0.19    612.72      1.00\n",
      "               default     -0.16      0.01     -0.16     -0.17     -0.15    322.31      1.00\n",
      "                 sigma      0.05      0.00      0.05      0.05      0.05    512.25      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [04:18<00:00,  7.74it/s, 127 steps of size 3.39e-02. acc. prob=0.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                            mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "        bayes_altitude      0.50      0.08      0.50      0.37      0.63    973.05      1.00\n",
      "       bayes_dew_point      0.64      0.66      0.65     -0.42      1.67    343.60      1.00\n",
      "        bayes_humidity      0.88      0.25      0.87      0.46      1.25    330.68      1.00\n",
      "        bayes_latitude     -0.02      0.08     -0.02     -0.16      0.10   1041.08      1.00\n",
      "       bayes_longitude     -0.16      0.07     -0.16     -0.27     -0.03    787.50      1.00\n",
      "  bayes_precipitations      9.53      0.65      9.54      8.54     10.64    845.12      1.00\n",
      "     bayes_temperature     -1.03      0.54     -1.04     -1.85     -0.11    348.47      1.00\n",
      "  bayes_wind_direction      0.68      0.22      0.68      0.30      1.02    805.39      1.00\n",
      "      bayes_wind_speed      5.31      0.25      5.32      4.91      5.73    395.92      1.00\n",
      "               default     -0.10      0.14     -0.10     -0.32      0.14    632.88      1.00\n",
      "                 sigma      4.15      0.01      4.15      4.13      4.17   1313.66      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "MAPE :  120.95708945598557\n",
      "Mean Absolute Error :  2.478234124218667\n"
     ]
    }
   ],
   "source": [
    "ratios = [0.75, 0.85] #[0.01, 0.1, 0.25, 0.5] # ,\n",
    "\n",
    "mape_prediction = []\n",
    "mae_prediction = []\n",
    "\n",
    "for ratio in ratios:\n",
    "    print('ratio', ratio)\n",
    "    dataset, nanidx_wd, nanidx_prec, true_wind_direction, true_precipitations = get_data_imputation_wd_prec(ratio)\n",
    "\n",
    "    print(len(nanidx_wd))\n",
    "\n",
    "    print(dataset['wind_direction'].isna().sum())\n",
    "    print(dataset['precipitations'].isna().sum())\n",
    "\n",
    "    # Here the dataset contains the data with nan in columns wind_direction and precipitaions\n",
    "    _, _, data, data_to_impute, wind_direction = prepare_data_imputation_wd(dataset, nanidx_wd)\n",
    "\n",
    "# IMPUTATION WIND_DIRECTION\n",
    "\n",
    "    mcmc_imputation = MCMC(NUTS(model_inference_wind_direction), num_warmup=1000, num_samples=1000)\n",
    "    mcmc_imputation.run(random.PRNGKey(0), **data, wind_direction=wind_direction, nan_columns = [], mu=dict(), sigma=dict(), prec_nan=True)\n",
    "    # Print the statistics of posterior samples collected during running this MCMC instance. (documentation)\n",
    "    mcmc_imputation.print_summary()\n",
    "\n",
    "    posterior_imputation = mcmc_imputation.get_samples()\n",
    "    imputed_wind_direction = Predictive(model_inference_wind_direction, posterior_imputation)(random.PRNGKey(1), **data_to_impute,  nan_columns = [], prec_nan=True)[\"wind_direction\"]\n",
    "    imputed_wind_direction = imputed_wind_direction.mean(axis=0)\n",
    "\n",
    "    # here we replace the nans in wind_direction by the predicted values\n",
    "    # dataset_to_impute['wind_direction'] = imputed_wind_direction\n",
    "    # dataset = pd.concat([dataset, dataset_to_impute], axis=0)\n",
    "\n",
    "\n",
    "    dataset.loc[nanidx_wd, 'wind_direction'] = imputed_wind_direction\n",
    "\n",
    "    # IMPUTATION PRECIPITATIONS\n",
    "\n",
    "    dataset, dataset_to_impute, data, data_to_impute, precipitations = prepare_data_imputation_prec(dataset, nanidx_prec)\n",
    "\n",
    "    mcmc_imputation = MCMC(NUTS(model_inference_precipitation), num_warmup=1000, num_samples=1000)\n",
    "    mcmc_imputation.run(random.PRNGKey(0), **data, precipitations=precipitations, nan_columns = [], mu=dict(), sigma=dict())\n",
    "    # Print the statistics of posterior samples collected during running this MCMC instance. (documentation)\n",
    "    mcmc_imputation.print_summary()\n",
    "\n",
    "    posterior_imputation = mcmc_imputation.get_samples()\n",
    "    imputed_precipitation = Predictive(model_inference_precipitation, posterior_imputation)(random.PRNGKey(1), **data_to_impute,  nan_columns = [])[\"precipitations\"]\n",
    "    imputed_precipitation = imputed_precipitation.mean(axis=0)\n",
    "\n",
    "    # PREPARE DATA FOR PREDICTION\n",
    "\n",
    "    dataset_to_impute['precipitations'] = imputed_precipitation\n",
    "    dataset = pd.concat([dataset, dataset_to_impute], axis=0)\n",
    "    ground_truth = dataset.ground_truth.values\n",
    "    del dataset['ground_truth']\n",
    "\n",
    "    print(dataset['wind_direction'].isna().sum())\n",
    "    print(dataset['precipitations'].isna().sum())\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dataset, ground_truth, test_size=0.33)\n",
    "\n",
    "    # print(dataset['wind_direction'].isna().sum())\n",
    "\n",
    "    data_train = dict(\n",
    "        latitude = x_train.latitude.values,\n",
    "        longitude = x_train.longitude.values,\n",
    "        altitude = x_train.altitude.values,\n",
    "        wind_direction = x_train.wind_direction.values,\n",
    "        wind_speed = x_train.wind_speed.values,\n",
    "        temperature = x_train.temperature.values,\n",
    "        humidity = x_train.humidity.values,\n",
    "        dew_point = x_train.dew_point.values,\n",
    "        precipitations = x_train.precipitations.values,\n",
    "    )\n",
    "\n",
    "    data_test = dict(\n",
    "        latitude = x_test.latitude.values,\n",
    "        longitude = x_test.longitude.values,\n",
    "        altitude = x_test.altitude.values,\n",
    "        wind_direction = x_test.wind_direction.values,\n",
    "        wind_speed = x_test.wind_speed.values,\n",
    "        temperature = x_test.temperature.values,\n",
    "        humidity = x_test.humidity.values,\n",
    "        dew_point = x_test.dew_point.values,\n",
    "        precipitations = x_test.precipitations.values,\n",
    "    )\n",
    "\n",
    "    mcmc_prediction = MCMC(NUTS(model_ground_truth), num_warmup=1000, num_samples=1000)\n",
    "    mcmc_prediction.run(random.PRNGKey(0), **data_train, ground_truth=y_train, nan_columns = [], mu=dict(), sigma=dict())\n",
    "    # Print the statistics of posterior samples collected during running this MCMC instance. (documentation)\n",
    "    mcmc_prediction.print_summary()\n",
    "\n",
    "    posterior_prediction = mcmc_prediction.get_samples()\n",
    "    ground_truth_pred = Predictive(model_ground_truth, posterior_prediction)(random.PRNGKey(1), **data_test,  nan_columns = [])[\"ground_truth\"]\n",
    "    ground_truth_pred = ground_truth_pred.mean(axis=0)\n",
    "\n",
    "    print(\"MAPE : \", m_mape(y_test, ground_truth_pred))\n",
    "    mape_prediction.append(m_mape(y_test, ground_truth_pred))\n",
    "    print(\"Mean Absolute Error : \", mean_absolute_error(y_test, ground_truth_pred))\n",
    "    mae_prediction.append(mean_absolute_error(y_test, ground_truth_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "41060"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    len(imputed_wind_direction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mape_prediction =  [121.0717496822495, 120.95708945598557]\n",
      "mae_prediction =  [2.4638451731754847, 2.478234124218667]\n"
     ]
    }
   ],
   "source": [
    "print('mape_prediction = ', mape_prediction)\n",
    "print('mae_prediction = ', mae_prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}